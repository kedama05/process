Linear Classification

kNNにはいくつかの欠点があった。

1.  分類器は、すべてのトレーニングデータを記憶し、
    将来のテストデータとの比較のために保存する必要がある。

2.  テスト画像を分類することは、
    すべてのトレーニング画像との比較を必要とするので高価である。


Overview
ニューラルネットワークと畳み込みニューラルネットワーク全体に自然に拡張される
画像分類の強力なアプローチを開発しようとしている。

このアプローチには、スコア関数と損失関数という2つの主要な要素がある。

スコア関数: 生データをクラススコアにマッピングする
損失関数: 予測スコアとグラウンドトゥルーラベルとの間の一致を定量化する

次に、スコア関数のパラメータに関する損失関数を最小化する最適化問題としてこれをキャストする。


Parameterized mapping from images to label scores

画像のピクセル値を各クラスの信頼スコアにマッピングするスコア関数を定義する。


training dataset of images xi∈RD と過程(assume)する。
それぞれ label yi と関連付けられる。
ここで、i=1…N であり、 yi∈1…K である。
つまり、N個の例（それぞれ次元Dを持つ）とK個の異なるカテゴリがある。


CIFAR-10では、N = 50,000 imagesのトレーニングセット、それぞれD = 32 x 32 x 3 = 3072 pixelsと、 K = 10、10 distinct classes あるため。
raw image pixels をクラススコアにマッピングするスコア関数 f:RD↦RK を定義する。

Linear classifier.
このモジュールでは、間違いなく可能な最も単純な関数、線形マッピングから始める。
f(xi,W,b)=Wxi+b

上式では、image xi はすべてのピクセルをshape [D x 1]のシングルカラムベクトルにフラット化したものと仮定する。
マトリックス W (of size [K x D]) とベクトル b (of size [K x 1])は、ファンクションのparametersである。
CIFAR-10では、 xi はi-th image を[3072 x 1]にフラット化したすべてのピクセルを含み、
Wは[10 x 3072]、bは[10 x 1]なので、3072の数値(the raw pixel values)が関数に入り、10の数値 (the class scores).が出力されます。。

パラメータの Wは重み、bはバイアスベクトルと呼ばれる。
これは出力スコアに影響するが、実際のデータxiとは相互作用しないためである。
しかし、しばしば重みとパラメータの用語を同じ意味で使用する。


注意すべき点:
まず、1つの行列乗算 Wxi が、各分類器がWの行である10個の別個の分類器を並列に（各クラスに1つ）効果的に評価することに留意されたい。
（x私、y私）
このアプローチの利点は、学習データがパラメータW、bを学習するために使用されるが、学習が完了したら学習セット全体を破棄し、学習されたパラメータのみを保持できることである。これは、新しいテスト画像を単純に機能を通して転送し、計算されたスコアに基づいて分類することができるからである。

最後に、テスト画像を分類するには、行列の乗算と加算を1回行う必要がある。
これは、テスト画像とすべてのトレーニング画像を比較するよりもはるかに高速である。






