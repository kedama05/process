k - Nearest Neighbor Classifier
k-Nearest Neighbor Classifierと呼ばれるものを使用すると、より良い結果が得られる。

k-Nearest Neighbor Classifierでは、
トレーニングセット内で最も近い単一の画像を見つける代わりに、
最も近いk個の最も近い画像を見つけて、テスト画像のラベルに投票させる。

特に、k = 1の場合、Nearest Neighbor Classifierと同様になる。
kの値が高いほど平滑化効果があり、分類器は外れ値に対してより耐性がある。

外れ値のデータでは、予測が間違っているであろう小さな島々(予測データ)を作成する。

Nearest Neighbor Classifierでは、
すべての領域がいずれかのクラスの決定領域として分類されていた。
しかし、k-Nearest Neighbor Classifierでは、
どのクラスにも属さない灰色領域なるものがあり、
その領域のデータは近傍のクラスの投票の結びつき？によって分類される。

多くの場合にはk-Nearest Neighbor Classifierを用いるが、kを適切な値に設定する必要がある。


Validation sets for Hyperparameter tuning
ハイパーパラメータチューニングの検証セット

k-最近隣分類器は、kのための設定を必要とする。
ハイパーパラメータ: 分類する上での設定などにおける様々な選択肢

ハイパーパラメータを調整する目的でテストセットを使用することはできない。
マシンラーニングアルゴリズムを設計しているときは、テストセットを非常に貴重なリソースと考えるべき。
一番最後まで一度も触れないようにする。

テストセットを調整に使ってパフォーマンスを達成しても、その考え方はあまりにも楽観的で意味がない。
しかし、テストセットを最終段階におけるチェックに用いる場合には、分類機の一般化を測定する良い尺度となる。


幸いにもハイパーパラメータを調整する正しい方法がある。
トレーニングセットをわずかに小さなトレーニングセットと検証セットの2つに分ける。

例えば、50,000のトレーニング用データ持つCIFAR-10を使用すると、
トレーニングに49,000のトレーニング画像を使用し、検証のために1,000個を残す。
検証セットは、ハイパーパラメータを調整するための偽のテストセットとして使用される。

CIFAR-10の場合、これは次のようになる。

# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before
# recall Xtr_rows is 50,000 x 3072 matrix
Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation
Yval = Ytr[:1000]
Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train
Ytr = Ytr[1000:]

# find hyperparameters that work best on the validation set
validation_accuracies = []
for k in [1, 3, 5, 10, 20, 50, 100]:
  
  # use a particular value of k and evaluation on validation data
  nn = NearestNeighbor()
  nn.train(Xtr_rows, Ytr)
  # here we assume a modified NearestNeighbor class that can take a k as input
  Yval_predict = nn.predict(Xval_rows, k = k)
  acc = np.mean(Yval_predict == Yval)
  print 'accuracy: %f' % (acc,)

  # keep track of what works on the validation set
  validation_accuracies.append((k, acc))


トレーニングセットをトレーニングセットと検証セットに分割する。
すべてのハイパーパラメータの調整のために、検証セットを使用する。
最後に、テストセットを1回実行し、パフォーマンスを報告する。



Cross-validation.
トレーニングデータのサイズ（したがって検証データも）が小さい場合は、
相互検証(cross-validation)と呼ばれるより高度なパラメータ調整のためのより洗練されたテクニックを使用することがある。



実際には、クロスバリデーションは計算上高価になる可能性があるため、
単一の検証分割を行うことを優先してクロスバリデーションを避ける方が望ましい.

一般に、トレーニングのためのトレーニングデータの50％〜90％と、検証のための残りのデータに分割する。

ハイパーパラメータの数が多い場合は、より大きな検証分割を使用することが推奨される。

検証セット内のサンプル数が少ない場合(数百程度)、クロスバリデーションを使用する方が安全である。
典型的なfoldの数は、3倍、5倍または10倍のcross-validationである。



Pros and Cons of Nearest Neighbor classifier.

Nearest Neighbor classifier
Pros
実装および理解が非常に簡単
分類器は、訓練のための時間を要しない

Cons
1つごとに比較が必要なため、テスト時には計算コストがかかる

→deep neural networks は真逆でトレーニングに時間がかかり、テスト時にはコストがほとんどかからない。


Nearest Neighbor classifier

Approximate Nearest Neighbor
検索中に空間/時間の複雑さを伴う最近傍検索の正しさをトレードオフすることを可能にし、
通常、kdtreeの構築またはk-meansアルゴリズムの実行を含む前処理/索引付け段階に依存する。

