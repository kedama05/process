k - Nearest Neighbor Classifier
k-Nearest Neighbor Classifierと呼ばれるものを使用すると、より良い結果が得られる。

k-Nearest Neighbor Classifierでは、
トレーニングセット内で最も近い単一の画像を見つける代わりに、
最も近いk個の最も近い画像を見つけて、テスト画像のラベルに投票させる。

特に、k = 1の場合、Nearest Neighbor Classifierと同様になる。
kの値が高いほど平滑化効果があり、分類器は外れ値に対してより耐性がある。

外れ値のデータでは、予測が間違っているであろう小さな島々(予測データ)を作成する。

Nearest Neighbor Classifierでは、
すべての領域がいずれかのクラスの決定領域として分類されていた。
しかし、k-Nearest Neighbor Classifierでは、
どのクラスにも属さない灰色領域なるものがあり、
その領域のデータは近傍のクラスの投票の結びつき？によって分類される。

多くの場合にはk-Nearest Neighbor Classifierを用いるが、kを適切な値に設定する必要がある。


Validation sets for Hyperparameter tuning
ハイパーパラメータチューニングの検証セット

k-最近隣分類器は、kのための設定を必要とする。
ハイパーパラメータ: 分類する上での設定などにおける様々な選択肢

ハイパーパラメータを調整する目的でテストセットを使用することはできない。
マシンラーニングアルゴリズムを設計しているときは、テストセットを非常に貴重なリソースと考えるべき。
一番最後まで一度も触れないようにする。

テストセットを調整に使ってパフォーマンスを達成しても、その考え方はあまりにも楽観的で意味がない。
しかし、テストセットを最終段階におけるチェックに用いる場合には、分類機の一般化を測定する良い尺度となる。


幸いにもハイパーパラメータを調整する正しい方法がある。
トレーニングセットをわずかに小さなトレーニングセットと検証セットの2つに分ける。

例えば、50,000のトレーニング用データ持つCIFAR-10を使用すると、
トレーニングに49,000のトレーニング画像を使用し、検証のために1,000個を残す。
検証セットは、ハイパーパラメータを調整するための偽のテストセットとして使用される。

CIFAR-10の場合、これは次のようになる。

# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before
# recall Xtr_rows is 50,000 x 3072 matrix
Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation
Yval = Ytr[:1000]
Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train
Ytr = Ytr[1000:]

# find hyperparameters that work best on the validation set
validation_accuracies = []
for k in [1, 3, 5, 10, 20, 50, 100]:
  
  # use a particular value of k and evaluation on validation data
  nn = NearestNeighbor()
  nn.train(Xtr_rows, Ytr)
  # here we assume a modified NearestNeighbor class that can take a k as input
  Yval_predict = nn.predict(Xval_rows, k = k)
  acc = np.mean(Yval_predict == Yval)
  print 'accuracy: %f' % (acc,)

  # keep track of what works on the validation set
  validation_accuracies.append((k, acc))


トレーニングセットをトレーニングセットと検証セットに分割する。
すべてのハイパーパラメータの調整のために、検証セットを使用する。
最後に、テストセットを1回実行し、パフォーマンスを報告する。



Cross-validation.
トレーニングデータのサイズ（したがって検証データも）が小さい場合は、
相互検証(cross-validation)と呼ばれるより高度なパラメータ調整のためのより洗練されたテクニックを使用することがある。



実際には、クロスバリデーションは計算上高価になる可能性があるため、
単一の検証分割を行うことを優先してクロスバリデーションを避ける方が望ましい.

一般に、トレーニングのためのトレーニングデータの50％〜90％と、検証のための残りのデータに分割する。

ハイパーパラメータの数が多い場合は、より大きな検証分割を使用することが推奨される。

検証セット内のサンプル数が少ない場合(数百程度)、クロスバリデーションを使用する方が安全である。
典型的なfoldの数は、3倍、5倍または10倍のcross-validationである。



Pros and Cons of Nearest Neighbor classifier.

Nearest Neighbor classifier
Pros
実装および理解が非常に簡単
分類器は、訓練のための時間を要しない

Cons
1つごとに比較が必要なため、テスト時には計算コストがかかる

→deep neural networks は真逆でトレーニングに時間がかかり、テスト時にはコストがほとんどかからない。


Nearest Neighbor classifier

Approximate Nearest Neighbor
検索中に空間/時間の複雑さを伴う最近傍検索の正しさをトレードオフすることを可能にし、
通常、kdtreeの構築またはk-meansアルゴリズムの実行を含む前処理/索引付け段階に依存する。


Summary

Image Classificationの問題を紹介しました。
ここでは、すべて1つのカテゴリにラベル付けされた一連の画像が与えられています。
次に、新しい一連のテスト画像についてこれらのカテゴリを予測し、予測の精度を測定するように求められます。

Nearest Neighborクラシファイアと呼ばれる単純な分類器を導入しました。
この分類子に関連する複数のハイパーパラメータ（kの値や例を比較するための距離の型など）があり、
それらを選択する明白な方法がないことがわかりました。

これらのハイパーパラメータを設定する正しい方法は、訓練データを2つに分割することです。
訓練セットと偽のテストセットです。
これを検証セットと呼びます。
我々は、異なるハイパーパラメータ値を試し、バリデーションセットで最高のパフォーマンスをもたらす値を保持します。

訓練データが不足している場合は、相互検証と呼ばれる手順を検討しました。

最良のハイパーパラメータが見つかると、それらを修正し、実際のテストセットについて単一の評価を実行します。

Nearest Neighborは、CIFAR-10で約40％の精度を得ることができます。
実装は簡単ですが、トレーニングセット全体を保存する必要があり、テストイメージで評価するのに費用がかかります。

最後に、生のピクセル値に対するL1距離またはL2距離の使用は、距離が意味内容よりも画像の背景および色分布とより強く相関するため、適切ではないことがわかりました。
