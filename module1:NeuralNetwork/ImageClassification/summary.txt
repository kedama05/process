
Summary

Image Classificationの問題を紹介しました。
ここでは、すべて1つのカテゴリにラベル付けされた一連の画像が与えられています。
次に、新しい一連のテスト画像についてこれらのカテゴリを予測し、予測の精度を測定するように求められます。

Nearest Neighborクラシファイアと呼ばれる単純な分類器を導入しました。
この分類子に関連する複数のハイパーパラメータ（kの値や例を比較するための距離の型など）があり、
それらを選択する明白な方法がないことがわかりました。

これらのハイパーパラメータを設定する正しい方法は、訓練データを2つに分割することです。
訓練セットと偽のテストセットです。
これを検証セットと呼びます。
我々は、異なるハイパーパラメータ値を試し、バリデーションセットで最高のパフォーマンスをもたらす値を保持します。

訓練データが不足している場合は、相互検証と呼ばれる手順を検討しました。

最良のハイパーパラメータが見つかると、それらを修正し、実際のテストセットについて単一の評価を実行します。

Nearest Neighborは、CIFAR-10で約40％の精度を得ることができます。
実装は簡単ですが、トレーニングセット全体を保存する必要があり、テストイメージで評価するのに費用がかかります。

最後に、生のピクセル値に対するL1距離またはL2距離の使用は、距離が意味内容よりも画像の背景および色分布とより強く相関するため、適切ではないことがわかりました。




Summary: Applying kNN in practice
要約：実際にkNNを適用する
実際にkNNを適用したい場合（うまくいけば画像ではなく、おそらくベースラインとしてのみ）、次のように進めてください：

1.  データの前処理：
    平均値と単位分散がゼロになるように、データ内のフィーチャ（イメージ内の1ピクセルなど）を正規化します。
    画像のピクセルは通常均質であり、広範囲に異なる分布を示さず、データの正規化の必要性が軽減されるため、
    このセクションでデータ正規化をカバーしないことを選択しました。

2.  データが非常に高次元である場合は、PCA（wiki ref、CS229ref、ブログ参照）、
    またはランダムプロジェクションなどの次元削減テクニックを使用することを検討してください。

3.  トレーニングデータを無作為に列車/分割に分割します。
    経験則として、データの70〜90％は通常列車分割に行きます。
    この設定は、あなたが持っているハイパラメーターの数と、どれだけの影響力があるかによって異なります。
    推定する多くのハイパーパラメータがある場合は、それらを効果的に推定するために、
    より大きなバリデーションセットを持つ側で誤っているべきです。
    検証データのサイズが気になる場合は、トレーニングデータを折り畳みに分割し、
    クロスバリデーションを実行することをお勧めします。
    計算予算を確保することができれば、クロスバリデーションを行う方が安全です（フォールドが増えるほど、コストは高くなります）。

4.  kの多くの選択肢（より良くなるなど）と異なる距離のタイプ（L1とL2は良い候補）
    についての検証データ（クロス検証の場合はすべてのフォールド）についてkNNクラシファイアをトレーニングして評価する

5.  kNNクラシファイアが長時間実行されている場合は、検索を高速化するために、
    ある近さの近傍ネイバーライブラリ（FLANNなど）を使用することを検討してください。

6.  最良の結果をもたらしたハイパーパラメータを注意してください。
    データのサイズが大きくなるため、検証データをトレーニングセットに組み込む場合、
    最適なハイパーパラメータが変更される可能性があるため、
    最適なハイパーパラメータを使用してフルトレーニングセットを使用する必要があるかどうかという疑問があります。
    実際には、最終的な分類器で検証データを使用せず、それがハイパーパラメータを推定する際に焼損すると考える。
    テストセット上で最良のモデルを評価する。
    テストセットの精度を報告し、結果をkNNクラシファイアのパフォーマンスと宣言します。