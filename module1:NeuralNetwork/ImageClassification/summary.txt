要約：実際にkNNを適用する
実際にkNNを適用したい場合（うまくいけば画像ではなく、おそらくベースラインとしてのみ）、次のように進めてください：

1.  データの前処理：
    平均値と単位分散がゼロになるように、データ内のフィーチャ（イメージ内の1ピクセルなど）を正規化します。
    画像のピクセルは通常均質であり、広範囲に異なる分布を示さず、データの正規化の必要性が軽減されるため、
    このセクションでデータ正規化をカバーしないことを選択しました。

2.  データが非常に高次元である場合は、PCA（wiki ref、CS229ref、ブログ参照）、
    またはランダムプロジェクションなどの次元削減テクニックを使用することを検討してください。

3.  トレーニングデータを無作為に列車/分割に分割します。
    経験則として、データの70〜90％は通常列車分割に行きます。
    この設定は、あなたが持っているハイパラメーターの数と、どれだけの影響力があるかによって異なります。
    推定する多くのハイパーパラメータがある場合は、それらを効果的に推定するために、
    より大きなバリデーションセットを持つ側で誤っているべきです。
    検証データのサイズが気になる場合は、トレーニングデータを折り畳みに分割し、
    クロスバリデーションを実行することをお勧めします。
    計算予算を確保することができれば、クロスバリデーションを行う方が安全です（フォールドが増えるほど、コストは高くなります）。

4.  kの多くの選択肢（より良くなるなど）と異なる距離のタイプ（L1とL2は良い候補）
    についての検証データ（クロス検証の場合はすべてのフォールド）についてkNNクラシファイアをトレーニングして評価する

5.  kNNクラシファイアが長時間実行されている場合は、検索を高速化するために、
    ある近さの近傍ネイバーライブラリ（FLANNなど）を使用することを検討してください。

6.  最良の結果をもたらしたハイパーパラメータを注意してください。
    データのサイズが大きくなるため、検証データをトレーニングセットに組み込む場合、
    最適なハイパーパラメータが変更される可能性があるため、
    最適なハイパーパラメータを使用してフルトレーニングセットを使用する必要があるかどうかという疑問があります。
    実際には、最終的な分類器で検証データを使用せず、それがハイパーパラメータを推定する際に焼損すると考える。
    テストセット上で最良のモデルを評価する。
    テストセットの精度を報告し、結果をkNNクラシファイアのパフォーマンスと宣言します。