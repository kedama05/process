MegDet: A Large Mini-Batch Object Detector  [11 Apr 2]


Abstract

R-CNN、Fast / Faster R-CNNから
最近のマスクR-CNNおよびRetinaNetまでの深い学習の時代におけるオブジェクト検出の開発は、
主に新規ネットワーク、新しいフレームワーク、または損失設計から来ています。

しかしながら、
深いニューラルネットワークのトレーニングのための重要な要素であるミニバッチサイズは、
物体検出のために十分に研究されていない。

本稿では、大規模ミニバッチオブジェクト検出器（MegDet）を提案し、
最大256個のミニバッチサイズで最大128個のGPUを効果的に利用して
トレーニング時間を大幅に短縮できるようにする。


技術的には、
    ウォームアップ学習率ポリシーとCross-GPU Batch Normalizationをお勧めします。

これにより、
    大量のミニバッチ検出器をはるかに短い時間（例えば33時間から4時間）で
    うまく訓練することができます。

MegDetは、
    COCO2017チャレンジに対する私たちの提出（mmAP 52.5％）のバックボーンであり、
    ここで第1位の検出タスクを獲得しました。



1. Introduction

R-CNN、Fast / Faster R-CNNシリーズ、Mask R-CNNやRetinaNetのような
    最近のstate-of-theart検出器の精巧な作業から、
    →   CNNベースのオブジェクト検出には驚異的な進歩 がありました。

COCO [25]データセットを例にとると、
    Fast R-CNNの19.7 AP（10）からRetinaNetの39.1 AP（24）にわずか2年間で性能が向上しました。

この改善は主に、
    より良いバックボーンネットワーク[16]、新しい検出フレームワーク[31]、
    新規損失設計[24]、改善されたプーリング方法[5]、[14]などによるものである。


最近のCNNベースの画像分類の傾向は、
非常に大きな最小バッチサイズを使用してトレーニングを大幅にスピードアップします。

例えば、
    ResNet-50のトレーニングは、ミニバッチサイズ8,192または16,000を使用して
    1時間または13分で実行することができます
    （精度はほとんどまたはまったく犠牲になりません）。

契約では、
    ミニバッチサイズは、物体検出文献において非常に小さい（例えば、2~16）ままである。

したがって、本論文では、
    物体検出におけるミニバッチサイズの問題を研究し、
    大きなミニバッチサイズ物体検出器の訓練に成功するための技術的解決策を提示する。

小さなミニバッチサイズで何が問題になりますか？

    物体検出器R-CNNシリーズに由来する、2枚の画像のみを含むミニバッチは、
        高速R-CNNおよびR-FCNのような一般的な検出器に広く採用されている。

    RetinaNetおよびMask R-CNNのような最先端の検出器では、
        ミニバッチサイズは16に増加するが、
        現在の画像分類で使用されるミニバッチサイズ（例えば、256）と比較して
        →   依然として非常に小さい。


小さなミニバッチサイズにはいくつかの潜在的な欠点

    まず、
        トレーニング時間は非常に長いです。

        たとえば、ResNet152のCOCOトレーニングは、
        Titian XP GPUが8台あるマシンでミニバスサイズ16を使用して3日間かかります。

    第2に、
        小さなミニバッチサイズでのトレーニングは、
        バッチ正規化[20]（BN）のための正確な統計値を提供することができない。

        良好なバッチ正規化統計を得るために、
        ImageNet分類ネットワークのミニバッチサイズは、通常、
        現在のオブジェクト検出器設定で使用されるミニバッチサイズよりも
        かなり大きい256に設定される。


    最後に述べるが決して軽んずべきでないものであるが、
        小さなミニバッチ内の肯定的および否定的な訓練の例が不均衡になりやすく、
        最終的な精度が損なわれる可能性があります。

    図2は、不均衡なプラスとマイナスの提案を含むいくつかの例を示しています。

    表1は、異なるミニバッチサイズの2つの検出器の統計を
    COCOデータセットの異なる訓練エポックで比較しています。


単純に最小バッチサイズを増やすという課題は何ですか？

    画像分類の問題と同様に、我々が直面している主なジレンマは、
        「等価学習率ルール」[13,21]に従って、大規模な最小バッチサイズは通常、
        精度を維持するために大きな学習率を必要とすることである。

    しかし、オブジェクト検出における学習率が高いと、
    コンバージェンスが失敗する可能性が非常に高くなります。
    コンバージェンスを確実にするために学習率を小さくすると、
    結果が劣ることがよくあります。


上記のジレンマに取り組むために、以下のような解決策を提案する。

    まず、
        線形スケーリングルールの新しい説明を提示し、
        学習率を漸増させるための「ウォームアップ」学習率政策[13]を借りる。

        これにより、
            トレーニングのコンバージェンスが保証されます。

    次に、 
        精度とコンバージェンスの問題に対処するために、
        より良いBN統計のためにCross-GPU Batch Normalization（CGBN）を紹介します。
        CGBNは精度を向上させるだけでなく、トレーニングをより安定させる。

        これは、
            急速に増加する計算能力を業界から安全に享受できるため、重要です。

    私たちのMegDet（バックボーンとしてのResNet-50）は、
    128 GPUで4時間でCOCOトレーニングを完了することができ、さらに高い精度を達成します。

    対照的に、
    小型のミニバッチカウンターパートは33時間かかり、精度は低くなります。

つまり、図1に示すように、
    イノベーションサイクルをほぼ一桁上げてパフォーマンスを向上させることができます。

MegDetをベースに、COCO 2017 Detection Challengeの第1位を確保しました。


3. Approach

このセクションでは、
    Large Mini-Batch Detector（MegDet）を紹介し、
    より短い時間でトレーニングを終了し、より高い精度を達成します

3.1. Problems with Small Mini-Batch Size
3.1。小さなミニバッチサイズの問題

初期のCNNベースの検出器は、
    Faster-RCNNとR-FCNの2つのような非常に小さなミニバッチサイズを使用します。
RetinaNetやMask R-CNNのような最先端の検出器でも、
    バッチサイズは16に設定されています。

小さなミニバッチサイズでトレーニングするときは、いくつかの問題があります。
    
    まず、
        小さなミニバッチサイズをトレーニングに利用する場合は、
        より長いトレーニング時間をかけなければなりません。

        図1に示すように、
            16のミニバッチサイズに基づくResNet-50検出器のトレーニングには
            30時間以上かかります。

        元のミニバッチサイズ2の場合、
            トレーニング時間は1週間以上になる可能性があります。

    第二に、
        検出器の訓練では、
            バッチ標準化の統計値を修正し、
            小さなミニバッチサイズはBN層の再トレーニングには適用されないため、
            事前計算値をImageNetデータセットで使用します。

        COCOとImageNetの2つのデータセットが大きく異なるため、
        これは最適以下のトレードオフです。

    最後に、
        少なくとも正と負のサンプルの比率が非常に不均衡になる可能性があります。

        表1では、正と負の訓練例の割合の統計を示します。

        ミニバッチサイズが小さいことは、特に最初のステージで、
        より不均衡なトレーニングの例につながることがわかります。
            この不均衡は、全体の検出性能に影響を及ぼす可能性があります。

冒頭で説明したように、
    ミニバッチサイズを単純に大きくすることは、
    収束と正確さとの間のトレードオフに対処する必要があります。

この問題に対処するために、まず大きなミニバッチの学習率ポリシーについて説明します。


3.2. Learning Rate for Large Mini-Batch
3.2。 ラージミニバッチの学習率

学習率ポリシーは、SGDアルゴリズムと強く関連しています。
したがって、
    まず、
        物体検出ネットワークの損失構造を見直し、
            Nが最小バッチサイズであり、l(x,w)がタスク固有損失であり、l(w)が正則化損失である
                formula(1)
            を検討する。

        より高速なRCNN [31]フレームワークおよびその変形[6,23,14]では、
            l(xi,w)はRPN予測損失、RPNバウンディングボックス回帰損失、予測損失、
            および境界ボックス回帰損失で構成されます。

ミニバッチSGDの定義によれば、
    訓練システムは重みwに関して勾配を計算し、各繰り返し後に勾配を更新する必要がある。

    N^←k・Nのようなミニバッチのサイズが変化するとき、
        学習率rもトレーニングの効率を維持するために適応されるべきであると考えられる。

    以前の研究[21,13,39]は、
        新しい学習率をr^←k・rに変える線形スケーリング規則を使用している。

    大きなミニバッチN^の1つのステップは、
        小さなミニバッチNのk個の累積ステップの有効性と一致しなければならないため、
        学習率rにも同じ比率kを掛けて損失のスケーリングファクタに対抗する必要がある

    これは、SGDアップデートの勾配等価仮定(gradient equivalence assumption)[13]に基づいています。
        この経験則は、画像分類において十分に検証されており、
        物体検出には依然として適用可能であることがわかっている。

        しかし、解釈はより弱く、より良い仮定のために異なっている。
        However, the interpretation is different for a weaker and better assumption.

    画像分類では、
        すべての画像が1つの注釈しか持たず、
        l（x、w）は単純な形式のクロスエントロピーである。

    物体検出に関しては、
        全ての画像が異なるボックス注釈の数を有し、
        その結果、画像間でground-truth分布が異なる。

    2つのタスクの違いを考慮すると、
        異なるミニバッチサイズ間の勾配等価性の仮定は、
        オブジェクト検出において保持されにくい可能性がある。

    そこで、以下の分散分析に基づく別の説明を紹介する。

Variance Equivalence.
分散等価。

    勾配等価仮定(gradient equivalence assumption)とは異なり、
    勾配の分散はkステップの間は同じままであると仮定する。

    ミニバッチサイズNが与えられると、
        各サンプル∇l（xi、w）のiδに従う勾配であれば、
        l（x、w）上の勾配の分散は次のようになる。
            formula(2)
    
        同様に、大きなミニバッチN^ = k・Nに対して、次の式を得ることができます。
            formula(3)
        
        重み更新に等価性を期待する代わりに、ここでは、
            小さなミニバッチNのk個の累積ステップに等しい
            大きなミニバッチNの1つの更新の分散を維持したいと考えています。
            これを達成するために、我々は以下を持っている：
                formula(4)

    式（2）および（3）の中で、
        r^ = k・rならば、上記の等式(4)が成り立ち、
        これはr^について同じ線形スケーリング・ルールを与える。

    最終的なスケーリングの規則は同じですが、
        大規模なミニバッチの訓練では、勾配に関する同等の統計を維持できると考えているため、
        式（4）の分散等価性の仮定は弱いです。

ここでの分散分析が、
    幅広いアプリケーションでの学習率の深い理解に光を当てることを願っています。


Warmup Strategy.
ウォーミングアップ戦略。

    [13]で議論したように、
        線形スケーリングのルールは、重みの変化が劇的であるため、
        トレーニングの初期段階では適用できないことがあります。

    この実用的な問題に対処するために、[13]でLinear Gradual Warmupを借りる。
        つまり、
            rのように初めに学習率を十分に小さく設定します。
        次に、
            反復ごとにr^まで一定の速度で学習率を上げる。

    Warmup戦略はコンバージェンスに役立ちます。

しかし、
    実験で実証したように、より大きなミニバッチサイズ、
    例えば128または256では十分ではない。
    ↓
次に、
    大規模なミニバッチ訓練の主役であるCross-GPU Batch Normalizationを紹介します。


3.3. Cross-GPU Batch Normalizatio
3.3。クロスGPUバッチ正規化

バッチ正規化[20]は、
    非常に深い畳み込みニューラルネットワークを訓練するための重要な技法である。
    
    バッチ標準化がなければ、
        そのような深いネットワークを訓練すると、
        はるかに多くの時間が消費されたり、収束しなくなることさえあります。

    しかしながら、
        FPN [23]のような以前の物体検出フレームワークは、
            ImageNetの事前訓練モデルを用いてモデルを初期化し、
            その後、バッチ規格化層は微調整手順全体の間に固定される。

この作業では、オブジェクト検出のためにバッチ正規化を実行しようとします。
    分類ネットワークの入力イメージはしばしば224×224または299×299であり、
    32以上のイメージでは
    12ギガバイトのメモリを備えた単一のNVIDIA TITAN Xp GPUで十分であることは注目に値する。

このようにして、
    バッチ正規化は、各デバイス単独で計算することができる。

しかし、
    物体検出のためには、
        検出器が様々なスケールの物体を扱う必要があるため、
        その入力としてより高い解像度の画像が必要である。


[23]では、サイズ800×800の入力が使用され、
    1つのデバイス上の可能なサンプル数を大幅に制限しています。

したがって、
    より多くのサンプルから十分な統計を収集するために、
        複数のGPUを横切る バッチ正規化 を実行する必要があります。

    GPU間で バッチ正規化 を実装するには、
        すべてのデバイスで集計平均/分散統計を計算する必要があります。

    既存のディープ学習フレームワークのほとんどは、
        内部統計の変更を許可せずに高レベルのAPIのみを提供する
        cuDNN [4]のBN実装を利用しています。

    したがって、
        予備的な数式の観点からBNを実装し、
        統計を集約するために「AllReduce」操作を使用する必要があります。

    これらのきめ細かな表現は通常、
        ランタイムオーバーヘッドを大きくし、
        ほとんどのフレームワークではAllReduce操作が欠落しています。


図3は、Cross-GPU Batch Normalizationの実装を示したものである。
    合計でn個のGPUデバイスがある場合、
    まずデバイスkに割り当てられたトレーニング例に基づいて合計値skを計算する。

        すべてのデバイスからの合計値を平均化することによって、
            現在のミニバッチの平均値μBを取得します。
            この手順では、AllReduce操作が必要です。

    次に、各デバイスの分散を計算し、σ2 Bを得る。

        各デバイスにσ2 Bをブロードキャストした後、
        formula[y =γ√x-μBσ2 B +ρ+β]によって標準正規化を行うことができる。

    アルゴリズム1は詳細なフローを示します。

    私たちの実装では、
        NVIDIA集合通信ライブラリ（NCCL）を使用して、
        受信と放送のためのAllReduceオペレーションを効率的に実行します。

    同じマシン上のGPUでのみBNを実行することに注意してください。

    したがって、
        各GPUが2つの画像を保持できる場合、
        16個の画像のBN統計量を計算することができます。

        32または64画像でBNを実行するには、
        訓練速度をわずかに低下させることによってGPUメモリ消費を節約するために、
        サブ線形メモリ[3]を適用します。

次のセクションでは、我々の実験結果は、
CGBNが精度と収束の両方に及ぼす大きな影響を実証するであろう。


4. Experiments
私たちは
    トレーニング、検証、テストに分かれているCOCO Detection Dataset [25]の実験を行い、
    80のカテゴリと250以上の000のイメージを含んでいます。

我々は、
    ImageNet [8]を基幹ネットワークとし、
    フィーチャピラミッドネットワーク（FPN）[23]を検出フレームワークとして
    事前にトレーニングしたResNet-50 [16]を使用する。

    118,000以上のトレーニング画像上の検出器を訓練し、5000個の検証画像を評価する。

    運動量0.9のSGDオプティマイザを使用し、重量減少0.0001を採用します。
    ミニバッチサイズ16の基本学習率は0.02です。

他の設定については、
    セクション3.2で説明した線形スケーリングルールが適用されます。

大規模なミニバッチでは、
    GPUのメモリ制約を補うために、サブラインメモリ[3]と分散型トレーニングを使用します。

下記の2つのトレーニングポリシーがあります。

    1） normal
        スケール0.1を乗算し、
        エポック11で終了することによって、
        エポック8と10の学習率を下げる。

    2） long
        スケール0.1を乗算し、
        エポック17での学習率を半分にし、エポック18で終了することで、
        エポック11と14での学習率を減少させます。

指定されていない限り、私たちはnormalポリシーを使用します。


4.1. Large mini-batch size, no BN
4.1。 大きなミニバッチサイズ、BNなし

    バッチの正規化を行わずに、さまざまなミニバッチサイズの設定を開始します。

    我々は、
        ミニバッチサイズ16,32,64および128で実験を行う。

        ミニバッチサイズ32では、
            ウォーミングアップ戦略を使用しても、
            トレーニングに失敗する可能性があることがわかりました。

        ミニサイズ64の場合、
            ウォームアップでも収束するようにトレーニングを管理することはできません。
            トレーニングを収束させるには、学習率を半減させる必要があります。

        ミニバッチサイズ128では、
            ウォームアップとハーフラーニングの両方の速度でトレーニングが失敗しました。

    COCO検証セットの結果を表2に示します。

    1） ミニバッチサイズ32は、
            16を使用したベースラインと比較して、
            精度の低下なしにほぼ直線的な加速を達成しました。

    2） 学習率が低い（ミニバッチサイズで64）と、精度が著しく低下する。

    3） ウォームアップ戦略であっても、
        ミニバッチサイズと学習率が大きい場合、
        トレーニングは難しく、または不可能です。


4.2. Large mini-batch size, with CGBN
4.2。 大型ミニバッチサイズ、CGBN付

    実験のこの部分は、バッチ標準化で訓練されています。

    最初の重要な点は、
        ウォームアップ戦略とCGBNを組み合わせると、
        ミニバッチサイズに関係なく、すべてのトレーニングが容易に収束することです。

    これは、
        小さい学習率を使用することによる精度の低下を心配する必要がないため、顕著です。

    主な結果は表3に要約されている。以下の所見がある。

        第1に、
            ミニバッチサイズの成長において、
                精度はほぼ同じレベルのままであり、
                ベースライン（16ベース）よりも一貫して良好である。

            その一方で、
                ミニバッチサイズが大きくなると、トレーニングサイクルが短くなります。

            たとえば、
                128個のGPUを搭載した256回のミニバッチ実験では、
                COCOトレーニングは4.1時間で終了します。
            
                これは、33.2時間のベースラインと比較して8倍の加速を意味します。


        第2に、
            最良のBNサイズ（BN統計の画像数）は32です。
            
            あまりにも少ない画像、例えば 2、4、または8の場合、
                BN統計は非常に不正確であり、結果としてパフォーマンスが低下します。

            しかし、サイズを64に増やすと、精度が低下します。
                これは、画像分類とオブジェクト検出タスクとの間の不一致を示す。

        第3に、
            表3の最後の部分では、長期トレーニング方針を検討する。

            トレーニング時間が長ければ、精度が少し高くなります。

            例えば、
                「32（長く）」はその対応（37.8 vs。37.3）よりも優れています。

            ミニバッチサイズが16より大きい場合、
            最終結果は非常に構成され、真の収束を示します。

        最後に、
            図4では、16（long）と256（long）のepoch-by-epoch mmAPカーブを描画します。

            256（長い）は
                初期のエポックでは悪化しますが、
                最後の段階（2番目の学習率減衰後）で16（長く）続きます。

    この観察は、画像分類[13,39]のものとは異なり、
    精度曲線および収束スコアの両方が、異なるミニバッチサイズ設定の間で非常に近い。

私たちはこの現象を将来の仕事として理解しています。


5. Concluding Remark
    私たちは大型ミニバッチサイズ検出器を発表しました。
    これは、はるかに短い時間でより良い精度を達成しました。

    これは、私たちの研究サイクルが大幅に加速されたために顕著です。

    その結果、私たちはCOCO2017検出の課題の1位を獲得しました。
    詳細は付録にあります。


Appendix

私たちはMegDetに基づいて、
OHEM、atural convolution、より強固な基盤モデル、
大規模カーネル、セグメンテーション監視、多様なネットワーク構造、
コンテキストモジュール、ROIAlign、
COCO 2017 Object Detection Challengeの
マルチスケールトレーニングとテストなどの技術を統合します。

検証セットで50.5 mmAP、テストデベロッパーで50.6 mmAPを得ました。

4つの検出器のアンサンブルは最終的に52.5を達成した。

表4は、COCO2017チャレンジのリーダーボードからのエントリーをまとめたものです。

図5は、いくつかの例示的な結果を示す。