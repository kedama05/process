MegDet: A Large Mini-Batch Object Detector

Abstract
1. Introduction
2. Related Work
3. Approach
    3.1. Problems with Small Mini-Batch Size
    3.2. Learning Rate for Large Mini-Batch
    3.3. Cross-GPU Batch Normalizatio
4. Experiments
    4.1. Large mini-batch size, no BN
    4.2. Large mini-batch size, with CGBN
5. Concluding Remark
Appendix



Abstract
    本稿では、
        大規模ミニバッチオブジェクト検出器（MegDet）を提案
            最大256個のミニバッチサイズで最大128個のGPUを効果的に利用
            →   トレーニング時間を大幅に短縮

    技術的提案
        warmup learning rate policy (ウォームアップ学習率ポリシー)
        Cross-GPU Batch Normalization (Cross-GPU バッチ正規化)

    成果
        COCO2017チャレンジで第1位の検出タスクを獲得 （mmAP 52.5％）


1. Introduction

    これまでに
        より良いバックボーンネットワーク[16]、新しい検出フレームワーク[31]、
        新規損失設計[24]、改善されたプーリング方法[5]、[14]などによって精度改善が行われてきた

    最近のCNNベースの画像分類の傾向
        非常に大きな最小バッチサイズを使用した、トレーニングの大幅なスピードアップ

            ex)
                ResNet-50のトレーニングは、
                ミニバッチサイズ8,192または16,000を使用して
                1時間または13分で実行することができる
                （精度はほとんどまたはまったく犠牲にならない）

        ミニバッチサイズは、物体検出文献において非常に小さい（例えば、2~16）まま
                                        ↓
                物体検出におけるミニバッチサイズの問題を研究し、
    大きなミニバッチサイズ物体検出器の訓練に成功するための技術的解決策を提示する。


    小さなミニバッチサイズでの問題
        潜在的な欠点
            1.  トレーニング時間が非常に長い
            2.  Batch Normalization[20]（BN）のための正確な統計値を提供できない
            3.  訓練の例が不均衡になりやすく、最終的な精度が損なわれる可能性がある
        

    最小バッチサイズを増やす上での課題
        "equivalent learning rate rule"[13,21]に従って、
            大規模な最小バッチサイズは、精度を維持するために大きな学習率を必要とする

        オブジェクト検出において
            学習率を高くする:   収束が失敗する可能性が非常に高くなる
            学習率を小さくする: 収束を確実にするが、結果が劣ることがよくある
        
        ジレンマの解決策
            1.  “warmup” learning rate policy[13]
                トレーニングの収束が保証される

            2.  Cross-GPU Batch Normalization（CGBN）
                精度を向上させるだけでなく、トレーニングをより安定させる
                急速に増加する計算能力をindustryから安全に享受できる

        
    MegDet: 128 GPUで4時間でCOCOトレーニングを完了し, 高精度
    小型のミニバッチカウンターパート: 33時間かかり, 低精度

    イノベーションサイクルをほぼ一桁上げてパフォーマンスを向上させることができる
    MegDetをベースに、COCO 2017 Detection Challengeの第1位を確保


2. Related Work
    CNN-based detectors
        現在はCNNベースの検出器が主流
        既存のCNNベースの検出器を大まかに2つのカテゴリに分けることができる
            1段検出器
                SSN [26]、YOLO [29,30]、最近のRetinaNet [24]など
            2段検出器
                FAST RCNN [31]、R-FCN [6]およびMask-RCNN[33] [14]など
            
        2段検出器
            R-CNN [11]
                Selective Search [37]を使用して一連のregion proposalsを生成し、
                WarpされたパッチをCNN認識モデルで分類

            Fast-RCNN [10]
                Spatial Pyramid Pooling（SPP）をROIPoolingに単純化
                    妥当なパフォーマンスが得られているが、
                    Selective Searchなどの従来の方法では依然として提案を生成する

            Faster-RCNN [31]
                従来のregion proposal method を Region Proposal Network（RPN）に置き換え、
                end-to-endの検出フレームワークを提案
            
            R-FCN [6]
                位置精度の高い pooling を導入して速度-精度のトレードオフを得る
                    最近の研究は、検出性能の向上に重点を置いている

            Deformable ConvNets [7]
                学習されたオフセットを使用
                    フィーチャマップの異なる位置を畳み込み
                    ネットワークにオブジェクトに集中させる

            FPN [23]
                feature pyramid技術を導入し、小さな物体の検出に大きな進展をもたらす
                    FPNは精度と実装の間に良いトレードオフを提供するため、
                    既定の検出フレームワークとしてこれを使用する

            Mask R-CNN [14]
                alignment issueに対処するために、ROIAlignを導入
                    オブジェクト検出とインスタンスセグメンテーションの両方について
                    最先端の結果を達成する
            
            1段検出器
                提案および精製ステップを含む2段検出器とは異なり、
                通常より高速で動作する

            YOLO [29,30]
                7×7グリッドに基づく分類と回帰結果を得るために

                完全に接続されたレイヤーが畳み込みネットワークに続いている
            SSD [26]
                異なるアンカースケールを対象とする
                異なるフィーチャレイヤを備えた完全な畳み込みネットワークを提示

            RetinaNet
                焦点損失(focal loss)に基づいて[24]に導入
                1段検出器の誤検出を大幅に低減

    
    Large mini-batch training
        大規模なミニバッチ訓練は、画像分類における積極的な研究課題

        [13]    ResNet50に基づくimagenetトレーニングを1時間で終了

        [39]    分類精度を損なうことなく
                ResNet50トレーニングを31分で終えることができるトレーニング設定を示す

        [17]    大型ミニバッチと小型ミニバッチ間の一般化のギャップを調べ、
                ギャップをなくすための新しいモデルとアルゴリズムを提案

        物体検出のための大規模なミニバッチ訓練の話題はほとんど議論されていない

    



3. Approach
    3.1. Problems with Small Mini-Batch Size
        小さなミニバッチサイズでトレーニングする問題
            1.  長いトレーニング時間
            2.  Batch Normalization(BN)レイヤの再トレーニングには適用されない
                    バッチ正規化の統計を修正し、事前計算値をImageNetデータセットで使用
            3.  positive と negativeのサンプルの比率が非常に不均衡になる
                    全体の検出性能に影響を及ぼす可能性がある


    3.2. Learning Rate for Large Mini-Batch
        学習率ポリシーは、SGDアルゴリズムと強く関連する
            object detection networkの損失構造を見直し、式(1)を検討する
                L(x,w) = 1/N ΣN i=1 l(x_i,w) + λ/2||w||22
                        = l(x,w) + l(w)                     (1)
                l(x,w): タスク固有損失
                l(w):   正則化損失

            より高速なRCNN [31]フレームワークおよびその変形[6,23,14]では、
                l(xi,w):    RPN予測損失、RPN bounding box回帰損失、予測損失、
                            およびbounding box回帰損失で構成される


        ミニバッチSGDの定義によると
            訓練システムは重みwに関して勾配を計算し、各繰り返し後に勾配を更新する必要がある
                N^←k・Nのようなミニバッチのサイズが変化するとき、
                学習率rもトレーニングの効率を維持するために適応されるべき

            新しい学習率をr^←k・rに変える線形スケーリング規則を使用している[21,13,39]

            大きなミニバッチN^の1つのステップ
                小さなミニバッチNのk個の累積ステップの有効性と一致する必要がある
                →   学習率rにも同じ比率kを掛けて損失のスケーリングファクタに対抗する

                SGDアップデートの勾配等価仮定(gradient equivalence assumption)[13]に基づく
                    物体検出には依然として適用可能

        画像分類では、
            すべての画像が1つの注釈しか持たず、
            l（x、w）は単純な形式のクロスエントロピー

        物体検出に関しては、
            全ての画像が異なるボックス注釈の数を有し、
            その結果、画像間でground-truth分布が異なる

        2つのタスクの違いを考慮すると、
            異なるミニバッチサイズ間の勾配等価性の仮定は、
            オブジェクト検出において保持されにくい可能性がある

        Variance Equivalence.
            勾配等価仮定(gradient equivalence assumption)とは異なり、
            勾配の分散はkステップの間は同じままであると仮定

        ミニバッチサイズN、各サンプル∇l（xi、w）のiδに従う勾配なら

            l（x、w）上の勾配の分散:
                Var(∇l(x,w_t)) = 1/N^2 Σi=1 N Var(∂l(x_i,w_t)/∂w_t)
                                = 1/N^2 × (N･σ_l^2)
                                = 1/N σ_l^2                             (2)

            大きなミニバッチN^ = k・Nに対して、次の式を得る
                Var(∇l_N^(x,w_t)) = 1/kN σ_l^2                         (3)

            小さなミニバッチNのk個の累積ステップに等しい
            大きなミニバッチNの1つの更新の分散を維持する式:
                Var(r･Σt=1 k ･ Var(∇l^t_N^(x,w))) = r^2･k･Var(∇l_N(x,w))
                                                    ~~ r^^2Var(∇l_N^(x,w))  (4)

            r^ = k・rならば、上記の等式(4)が成り立ち
            r^について同じ線形スケーリング・ルールを与える
            
            最終的なスケーリングの規則は同じですが、
                大規模なミニバッチの訓練では、
                勾配に関する同等の統計を維持できると考えているため、
                式（4）の分散等価性の仮定は弱いです。


        Warmup Strategy.
            線形スケーリングのルール
                重みの変化が劇的であるため、
                トレーニングの初期段階では適用できないことがある
                →   Linear Gradual Warmup[13]を借りる
                    つまり
                        rのように初めに学習率を十分に小さく設定します
                    次に
                        反復ごとにr^まで一定の速度で学習率を上げる

            Warmup Strategyは収束に役立つ


    3.3. Cross-GPU Batch Normalization（CGBN）
        Batch Normalization[20]
            非常に深い畳み込みニューラルネットワークを訓練するための重要な技法

            バッチ標準化がなければ、
                そのような深いネットワークを訓練すると、
                はるかに多くの時間が消費されたり、収束しなくなる

            FPN [23]のような以前の物体検出フレームワーク
                ImageNetの事前訓練モデルを用いてモデルを初期化し、
                バッチ規格化層は微調整手順全体の間に固定される

            オブジェクト検出のためにバッチ正規化を実行しようとする

            物体検出のために
                検出器が様々なスケールの物体を扱う必要があるため、
                その入力としてより高い解像度の画像が必要

            より多くのサンプルから十分な統計を収集するために
                Cross-GPU Batch Normalizationを実行する必要がある

            GPU間で Batch Normalization を実装するには
                すべてのデバイスで集計平均/分散統計を計算する必要がある
            
                既存のディープ学習フレームワークのほとんど
                    内部統計の変更を許可せずに
                    高レベルのAPIのみを提供するcuDNN[4]のBN実装を利用

                →  予備的な数式の観点からBNを実装し、
                        統計を集約するために「AllReduce」操作を使用する必要がある
                    
                    これらのきめ細かな数式は通常、
                        ランタイムオーバーヘッドを大きくするため、
                        ほとんどのフレームワークではAllReduce操作が欠落している
            
            Cross-GPU Batch Normalizationの実装: 図3

                合計でn個のGPUデバイスがある場合
                    デバイスkに割り当てられたトレーニング例に基づいて合計値 sk を計算
                        すべてのデバイスからの合計値を平均化
                            現在のミニバッチの平均値 μB を取得

                        この手順では、AllReduce操作が必要

                    各デバイスの分散を計算し、σ^2_Bを取得
                        各デバイスにσ^2_Bをブロードキャスト
                            y = γ (x-μ_B/ √σ^2_B+ε) + β
                        によって標準正規化

            詳細なフロー: アルゴリズム1


            NVIDIA集合通信ライブラリ（NCCL）を使用して、
            受信と放送のためのAllReduceオペレーションを効率的に実行

            ＊同じマシン上のGPUでのみBNを実行する

            32または64画像でBNを実行するには、
                訓練速度をわずかに低下させることによってGPUメモリ消費を節約するために、
                サブ線形メモリ[3]を適用する。


4. Experiments
    トレーニング、検証、テストに分かれているCOCO Detection Dataset [25]の実験を行った
        80のカテゴリと250,000以上ののイメージを含む

    ResNet-50 [16]を使用
        backbone network: ImageNet [8]
        detection framework: Feature Pyramid Network(FPN) [23]
    
        118,000以上のトレーニング画像で検出器を訓練し、5000個の検証画像で評価
    
        慣性項(momentum) 0.9のSGD optimizerを使用し、重量減少0.0001を採用します。
        ミニバッチサイズ16の基本学習率: 0.02

        他の設定については、
            セクション3.2で説明した線形スケーリングルールが適用

        large mini-batchでは、
            GPUのメモリ制約を補うために、サブラインメモリ[3]と分散型トレーニングを使用
    
            2つのトレーニングポリシー
                1） normal
                    スケール0.1を乗算し、
                    エポック11で終了することによって、
                    エポック8と10の学習率を下げる。

                2） long
                    スケール0.1を乗算し、
                    エポック17での学習率を半分にし、エポック18で終了することで、
                    エポック11と14での学習率を減少させます。
    
                指定されていない限り、normalポリシーを使用

    4.1. Large mini-batch size, no BN
        バッチの正規化を行わずに、さまざまなミニバッチサイズの設定を開始

        ミニバッチサイズ16,32,64および128で実験を行う

        ミニバッチサイズ32:
            warmup戦略を使用しても、
            トレーニングに失敗する可能性がある

        ミニバッチサイズ64:
            warmupでも収束するようにトレーニングを管理することはできない
            トレーニングを収束させるには、学習率を半減させる必要がある

        ミニバッチサイズ128:
            warmupとハーフラーニングの両方の速度でトレーニングが失敗した
        
        COCO検証セットの結果: 表2

        1） ミニバッチサイズ32:
            16を使用したベースラインと比較して、
            精度の低下なしにほぼ直線的な加速を達成

        2） 学習率が低い（ミニバッチサイズで64）と、精度が著しく低下する。

        3） warmup戦略であっても、
            ミニバッチサイズと学習率が大きい場合、
            トレーニングは難しく、または不可能です。

    4.2. Large mini-batch size, with CGBN
        実験のこの部分は、バッチ標準化で訓練されている
        
        最初の重要な点
            warmup戦略とCGBNを組み合わせると、
            ミニバッチサイズに関係なく、すべてのトレーニングが容易に収束する
                小さい学習率を使用することによる精度の低下を心配する必要がないため、顕著
            
        主な結果: 表3
        
        以下の所見
        1.  ミニバッチサイズの成長において、精度はほぼ同じレベルのままで、
            ベースライン（16ベース）よりも一貫して良好

                ミニバッチサイズが大きくなると、トレーニングサイクルが短くなる


        2.  最良のBNサイズ（BN統計の画像数）は32
            
                あまりにも少ない画像、例えば 2、4、または8:
                    BN統計は非常に不正確であり、結果としてパフォーマンスが低下

                サイズを64に増やすと、精度が低下
                    画像分類とオブジェクト検出タスクとの間の不一致を示す


        3.  表3の最後の部分では、長期トレーニング方針を検討する。

                トレーニング時間が長ければ、精度が少し高くなる

                ミニバッチサイズが16より大きい:
                    最終結果は非常に構成され、真の収束を示す

        4.  図4では、16（long）と256（long）のepoch-by-epoch mmAPカーブを描画する

                256（long）は初期のエポックでは悪化するが、
                最後の段階（2長い番目の長い学習率減衰後）で16（long）と同程度。
    
                精度曲線および収束スコアの両方が、異なるミニバッチサイズ設定の間で非常に近い。



5. Concluding Remark
    大型ミニバッチサイズ検出器を発表した
        はるかに短い時間でより良い精度を達成した
        研究サイクルが大幅に加速されたために顕著

    その結果、COCO2017検出の課題の1位を獲得した