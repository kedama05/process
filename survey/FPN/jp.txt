抽象
FPNは、
    異なるスケールでオブジェクトを検出するための認識システムの基本コンポーネントです。
しかし、
    最近の深い学習オブジェクト検出器は、ピラミッド表現を避けている。

本稿では、
    深い畳み込みネットワークのマルチスケールのピラミッド階層を利用して、
    余分なコストをかけてフィーチャピラミッドを構築する。

横方向接続を有するトップダウンアーキテクチャは、
    すべてのスケールで高レベルセマンティック特徴マップを構築するために開発されている。
フィーチャピラミッドネットワーク（FPN）と呼ばれるこのアーキテクチャは、
    いくつかのアプリケーションで一般的なフィーチャ抽出ツールとして大きな改善を示す。

基本的なFaster R-CNNシステムでFPNを使用することにより、
COCO検出ベンチマークで最先端の単一モデル結果を達成し、
COCO 2016挑戦受賞者を含むすべての既存モデルを上回りました。

さらに、我々の方法は、
    GPU上で6FPSで実行
したがって、
    マルチスケールの物体検出に対する実用的かつ正確な解決策である。

コードは公開されます。


1. Introduction
非常に異なるスケールで物体を認識することは、コンピュータビジョンの基本的な課題。

画像ピラミッド上に構築されたフィーチャピラミッド
（これらのフィーチャ画像ピラミッドと略して）は、標準的な解決策の基礎を形成する（図1（a））

これらのピラミッドは、
    オブジェクトのスケールの変化が
    ピラミッドのレベルをシフトすることによって相殺されるという意味で、スケール不変

直観的には、
    このプロパティを使用すると、
        モデルで位置とピラミッドの両方のレベルでモデルをスキャンすることで、
        モデルが広範囲のスケールにわたってオブジェクトを検出できるようになります。

フィーチャイメージピラミッドは、
    手作業で設計されたフィーチャの時代に多用されていた。

DPM [7]のような物体検出器は、
    良好な結果（例えば、1オクターブ当たり10スケール）を達成するために
    高密度サンプリングを必要とするほど重大であった。

認識タスクのために、
    設計されたフィーチャは主に深い畳み込みネットワーク（ConvNets）[19、20]によって
    計算されたフィーチャで置き換えられました。

ConvNetsは、
    より高いレベルのセマンティクスを表すことができるだけでなく、
    スケールのばらつきに対してより頑強であり、
    したがって、
        単一の入力スケールで計算されたフィーチャからの認識を容易にする（図1（b））。

しかし、
    この頑強さでも、最も正確な結果を得るにはピラミッドが必要です。

ImageNet [33]およびCOCO [21]の検出問題の最近のトップエントリーでは、
    フィーチャイメージピラミッド（例えば、[16,35]）のマルチスケールテストが使用されている

画像ピラミッドの各レベルをフィーチャリングする主な利点は、
    高解像度レベルを含むすべてのレベルが
    意味的に強いマルチスケールフィーチャ表現を生成すること



それにもかかわらず、
    画像ピラミッドの各レベルをフィーチャリングすることには明らかな制限があります。
    推論時間はかなり増加し（例えば、4倍[11]）、
    Wこのアプローチは実際のアプリケーションでは実用的ではありません。W

さらに、
    画像ピラミッド上のエンドツーエンドの深いネットワークを訓練することは、
    メモリの点では実行不可能であり、悪用されると、
    画像ピラミッドはテスト時にのみ使用され、トレーニング/テスト時間推論の間に不一致が生じる。

これらの理由から、 
    FastかつFatster R-CNN [11,29]は、デフォルト設定でフィーチャイメージピラミッドを使用しないことを選択する。

しかし、
    画像ピラミッドは、マルチスケールのフィーチャ表現を計算する唯一の方法ではありません。

深いConvNetはレイヤーごとにフィーチャ階層を計算し、
    サブサンプリングレイヤでは
    フィーチャ階層は固有のマルチスケールピラミッド型を持ちます。

このネットワーク内のフィーチャ階層は、
    異なる空間解像度のフィーチャマップを生成しますが、
    異なる深度によって生じる大きな意味的ギャップを導入する。

高解像度マップは、
    オブジェクト認識のための表現能力を損なう低レベルの特徴を有する。


Single Shot Detector（SSD）[22]は、
    ConvNetのピラミッド型フィーチャ階層を
    フィーチャイメージピラミッドのように使用する最初の試みの1つです（図1（c））。

理想的には、
    SSDスタイルのピラミッドは、
    往路で計算された異なる層のマルチスケールフィーチャマップを再利用するため、
    コストがかかりません。

しかし、
    低レベルのフィーチャを使用することを避けるために、
    SSDは、
        既に計算されたレイヤを再利用することを控え、
        代わりにネットワーク内の高位から始まるピラミッド（例えば、VGGネットのconv4 3）
        を構築し、次いでいくつかの新しいレイヤを追加する。

したがって、
    フィーチャ階層の高解像度マップを再利用する機会が失われます。

これらは小さな物体の検出に重要であることを示しています。

この論文の目的は、
    ConvNetのフィーチャ階層のピラミッド形状を自然に活用しながら、
    すべてのスケールで強力なセマンティクスを持つフィーチャピラミッドを作成することです。

この目標を達成するために、我々は、
    高分解能、意味的に弱い特徴と低解像度の意味的に強い特徴を、
    トップダウン経路と横方向接続を組み合わせたアーキテクチャに依存する（図1（d））。

その結果、
    すべてのレベルで豊富なセマンティクスを持ち、
    単一の入力イメージスケールから迅速に構築されるフィーチャーピラミッドが得られます。

言い換えれば、
    表現力、速度、またはメモリを犠牲にすることなく
    フィーチャイメージピラミッドを置き換えるために使用できる
    ネットワーク内フィーチャピラミッドを作成する方法を示します。

最近の研究[28、17、8、26]では、
    トップダウン接続とスキップ接続を採用した同様のアーキテクチャが一般的です。

彼らの目標は、
    予測が行われるべき細かい解像度の単一の高レベルの特徴マップを生成することである（図2上）。

これに対し、我々の方法は、
    アーキテクチャ（例えば、オブジェクト検出）が
    各レベルで独立して行われるフィーチャピラミッドとしてアーキテクチャを活用する（図2下部）。

私たちのモデルは、
    フィーチャーされた画像ピラミッドをエコーし​​ますが、
    これらの作品では探究されていません。

我々は、
    検出とセグメンテーションのために様々なシステムで
    Feature Pyramid Network（FPN）と呼ばれる方法を評価する[11]、[29]、[27]。

ベルとホイッスルがなければ、
    我々はFPNと基本的なFaster R-CNN検出器をベースにした
    挑戦的なCOCO検出ベンチマークに関する最先端の単一モデル結果を報告し、
    競争優勝者の既存の重工業シングルモデルエントリーよりも優れています。

アブレーション実験では、
    バウンディングボックスの提案では、
    FPNがAverage Recall（AR）を8.0ポイント増加させます。

ResNetsのFaster R-CNNの強力な単一スケールのベースラインに比べて、
    オブジェクト検出のためにCOCOスタイルの平均精度（AP）を2.3ポイント、
    パスカルスタイルのAPを3.8ポイント改善しました[16]。

我々の方法は提案をマスクするために容易に拡張され、
    画像ピラミッドに大きく依存する最先端の方法よりも
    インスタンス分割ARおよびスピードを改善する。

さらに、私たちのピラミッド構造は、
    すべてのスケールでエンドツーエンドで訓練することができ、
    イメージピラミッドを使用してメモリ不能となるトレーニング/テスト時に一貫して使用されます。

結果として、FPNは、
    既存のすべての最先端の方法より高い精度を達成することができる。

さらに、この改善は、
    単一スケールベースラインを超えるテスト時間を増やすことなく達成される。

これらの進歩が将来の研究と応用を促進すると我々は考えている。

私たちのコードは一般に公開されます。


2. Related Work
手作りの機能と初期のニューラルネットワーク。

    SIFT特徴[25]は、もともとスケール空間極値で抽出され、特徴点マッチングに使用された。

    HOG特徴[5]、および後のSIFT特徴も、画像ピラミッド全体にわたって密に計算された。

    これらのHOGおよびSIFTピラミッドは、
        画像分類、物体検出、人間の姿勢推定などのために、多くの研究で使用されてきました。

    フィーチャ化画像ピラミッドを迅速に計算することにも大きな関心が寄せられている。

    ドル[6]は、
        最初にまばらにサンプリングされた（スケールで）ピラミッドを計算し、
        次に欠落したレベルを補間することによって、高速ピラミッド計算を実証した。

    HOGとSIFTの前に、
        ConvNets [38,32]による顔検出の初期の研究は、
        画像ピラミッド上の浅いネットワークを計算して、スケール間の顔を検出しました。

Deep ConvNetオブジェクト検出器。

    近代的なConvNets [19]の開発により、
        OverFeat [34]やR-CNN [12]のような物体検出器は、精度の劇的な改善を示した。

    OverFeatは、
        ConvNetを画像ピラミッド上に
        スライディングウィンドウ検出器として適用することにより、
        初期ニューラルネットワーク顔検出器と同様の戦略を採用しました。

    R-CNNは、
        ConvNetで分類する前に
        各提案をスケール正規化した地域提案ベースの戦略[37]を採用しました。

    SPPnet [15]は、
        そのような領域ベースの検出器が、
        単一の画像スケールで抽出された特徴マップ上に
        はるかに効率的に適用できることを示した。

    Fast R-CNN [11]やFaster R-CNN [29]のような最近のより正確な検出方法は、
        精度と速度のトレードオフが良いため、
        単一のスケールから計算されたフィーチャを使用しています。

    しかし、マルチスケールの検出は、
        特に小さなオブジェクトの場合、より優れたパフォーマンスを示します。

複数のレイヤーを使用するメソッド。

    最近の多くのアプローチでは、
        ConvNetの異なるレイヤーを使用して検出とセグメント化を改善しています。

    FCN [24]は、
        セマンティックセグメンテーションを計算するために、
        複数のスケールにわたって各カテゴリの部分スコアを合計します。

    Hypercolumns [13]は、
        オブジェクトインスタンスセグメンテーションのために同様のメソッドを使用します。

    他のいくつかのアプローチ（HyperNet [18]、ParseNet [23]、ION [2]）は、
        変換されたフィーチャを合計することと同等の、
        予測を計算する前に複数レイヤのフィーチャを連結します。

    SSD [22]およびMS-CNN [3]は、
        フィーチャまたはスコアを結合することなく、
        フィーチャ階層の複数のレイヤでオブジェクトを予測します。

    最近の方法では、
        解像度とセマンティックレベルで低レベルのフィーチャマップを関連付ける
        横方向/スキップ接続を利用する方法があります
            （セグメンテーションのためのU-NetとSharpMask、
            顔検出のためのRecombinatorネットワーク、
            キーポイント推定のスタックド砂時計ネットワーク）


    Ghiasi et al。 [8]は、
        セグメント化を漸進的に改善するための
        FCNのためのラプラシアンピラミッドプレゼンテーションを提示する。

    これらの方法は、
        ピラミッド型のアーキテクチャを採用しているが、
        フィーチャ化されたピラミッド型のピラミッドとは異なり[5,7,34]、
        図2のように予測は独立して行われる（図2参照）複数のスケール間で
        物体を認識するために画像ピラミッドが依然として必要である[28]。


3. Feature Pyramid Networks

    私たちの目標は、
        低レベルから高レベルへのセマンティクスを持つ
        ConvNetのピラミッド型フィーチャ階層を活用し、
        全体にわたって高水準セマンティクスを備えたフィーチャピラミッドを構築すること

    得られたフィーチャピラミッドネットワークは一般的な目的であり、
        本論文ではスライディングウィンドウの提案者（Region Proposal Network、RPN）[29]と
        地域ベースの検出器（Fast R-CNN）[11]に焦点を当てる。

    また、6章でFPNとインスタンスセグメンテーションの提案を一般化する。

    我々の方法は、
        入力として任意のサイズの単一スケール画像を取り、
        完全に畳み込み的に複数のレベルで比例したサイズの特徴マップを出力する。

    このプロセスは、
        バックボーン畳み込みアーキテクチャ（例えば、[19,36,16]）とは無関係であり、
        この論文ではResNets [16]を使用して結果を示します。

    私たちのピラミッドの構造は、以下で紹介するように、
        ボトムアップ経路、トップダウン経路、および横方向接続を含む。

    Bottom-up pathway
        ボトムアップ経路は、
            バックボーンConvNetのフィードフォワード計算であり、
            スケーリングステップ2で複数のスケールで
            フィーチャマップからなるフィーチャ階層を計算します。

        多くの場合、同じサイズの出力マップを生成する層が多くあり、
            これらの層は同じネットワーク段階にあると言います。

        私たちのフィーチャーピラミッドでは、
            各ステージに1つのピラミッドレベルを定義します。

        フィーチャマップの参照セットとして、
            各ステージの最後のレイヤの出力を選択し、ピラミッドを作成します。

        この選択は、
            各ステージの最も深いレイヤーが最も強力な機能を持つ必要があるため、当然です。

        具体的には、ResNets [16]に対して、
            各ステージの最後の残差ブロックによって出力された
            機能アクティベーションを使用します。

        conv2、conv3、conv4、conv5出力の最後の残差ブロックの出力を{C2、C3、C4、C5}とし、
        入力画に対して{4,8,16,32}ピクセルのストライドを持つことに注意してください。

        大きなメモリフットプリントのためにconv1をピラミッドに含めることはできません。


    Top-down pathway and lateral connections
        トップダウン経路は、
            より高いピラミッドレベルの空間的に粗いが、意味的に強い、
            特徴マップをアップサンプリングすることによって、
            より高い解像度の特徴を幻覚化する。

        これらの特徴は、
            ボトムアップ経路から横方向接続を介して強化される。

        各横方向の接続は、
            ボトムアップパスとトップダウンパスから
            同じ空間サイズのフィーチャマップをマージします。

        ボトムアップのフィーチャマップは
            下位レベルのセマンティクスですが、
            アクティベーションはサブサンプル数が少なくなるほど
            より正確にローカライズされます。

        図3は、
            トップダウン特徴マップを構成するビルディングブロックを示す。

        より粗い解像度の特徴マップを用いて、
            空間分解能を2倍アップサンプリングする
            （簡略化のために最近接アップサンプリングを使用する）。

        次に、アップサム・プット・マップは、
            要素ごとの加算によって、
            対応するボトムアップ・マップとマージされる。
            （1×1畳み込み層を経てチャネル・ディメンションを削減する）

        このプロセスは、最高解像度のマップが生成されるまで反復されます。

        反復を開始するには、
            C5に1×1の畳み込みレイヤーを付けて、最も粗い解像度マップを作成するだけです。

        最後に、
            各マージドマップに3×3コンボリューションを追加して、
            アップサンプリングのエイリアシング効果を低減するための
            最終的なフィーチャマップを生成します。

        特徴マップのこの最終セットは、
            {C2、C3、C4、C5}に対応する{P2、P3、P4、P5}と呼ばれ、
            それぞれ同じ空間サイズである。













