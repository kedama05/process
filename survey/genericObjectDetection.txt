3.1 Region Based (Two Stage Framework)

p6
Faster RCNN
Different from Fast RCNN, the features used for regression in RPN have the same size.
RPN shares CONV features with Fast RCNN, thus enabling highly efficient region proposal computation.

RPN is a kind of FullyConvolutional Network (FCN) 
Faster RCNN is thus a purely CNN based framework without using handcrafted features.

VGG16 model: 5fps
画像ごとに300の提案を使用してPASCAL VOC 2007で最先端のオブジェクト検出


The initial Faster RCNN in [175] contains several alternating training steps.
This was then simplified by one step joint training in [176].
[175]の最初のより高速のRCNNには、いくつかの交互のトレーニングステップが含まれています。
これは、[176]の1ステップの共同訓練によって単純化された。


高速RCNNの開発と並行して、CNNベースの検出器の領域提案生成の役割を研究し、
CNNがFCレイヤではなくCONVでの正確なオブジェクト検出に十分な幾何情報を含むことを発見した 。

CNNに専ら依存する統合された、より単純で高速なオブジェクト検出器を構築し、
選択的探索などの領域提案生成方法を除去する可能性を証明した。



RFCN(Region based Fully Convolutional Network)
Faster RCNNはFast RCNNよりも一桁高速ですが、
領域ごとのサブネットワークがまだRoI（画像あたり数百RoI）ごとに適用される必要があった。
    ↓
RFCN検出器: 画像全体にわたって共有されているほぼすべての計算と巧みに畳み込む（隠されたFCレイヤーなし）

Faster RCNN
    RoIプーリング層の後の計算は共有できません。

自然なアイデア
    共有できない計算量を最小限に抑えること
    ↓
DaiはすべてのCONVレイヤを共有RoIサブネットワークを構築することを提案
    RoI作物は予測の前にCONVフィーチャの最後のレイヤから取得する。

    この単純な設計は、より深いCONVレイヤーがカテゴリ意味に対してより敏感で、
    翻訳には敏感ではないと推定される一方で、
    オブジェクト検出には翻訳差異を考慮したローカライゼーション表現が必要であると推定される。

この観察に基づいて、
    特殊なCONVレイヤーのバンクをFCN出力として使用
    より標準的なRoIプーリングとは異なるポジティブセンシティブRoIプーリングレイヤーを追加して、
    一連のポジションセンシティブスコアマップを作成

    ResNet101 [79]を備えたRFCNが頻繁により速いランニングタイムで
    Faster RCNNと同等の精度を達成できることを示した



Mask RCNN

RCNN
    概念的な単純性、効率性、柔軟性を念頭に置いて、
    より高速なRCNNを拡張することによって、
    ピクセル単位のオブジェクトインスタンスセグメンテーションに取り組むことを提案

Mask RCNN
    同一の第1ステージ（RPN）を有する同じ2ステージパイプラインを採用する。

    第2段階では、クラスおよびボックスオフセットを予測することと並行して、
    Mask RCNNは、各RoIに対してバイナリマスクを出力するブランチを追加する。

        新しいブランチ: CNN機能マップの上にある完全畳み込みネットワーク（FCN）

    RoIAlign層: 元のRoIプーリング（RoIPool）層によって引き起こされた不整合を回避するために
                ピクセルレベルの空間的対応を維持するために提案された

    Mask RCNNは、
    バックボーンネットワークResNeXt101-FPN [223,130]を使用すると、
    COCOオブジェクトインスタンスのセグメンテーションと
    バウンディングボックスオブジェクトの検出で最高の結果を達成

    訓練するのが簡単、一般化が容易、
    高速のRCNNにわずかなオーバーヘッドしか加えず、5FPSで結合



Light Head RCNN
    RFCNの検出速度を向上させるために、LiはLight Head RCNNを提案し、
    検出ネットワークの頭部を可能な限り軽くしてRoI領域の計算を減らした。

    大きなカーネルの分離可能な畳み込みを適用
    小さなチャンネル番号と安価なRCNNサブネットワークを持つ薄いフィーチャマップを作成
    速度と精度の優れたトレードオフにつながった




3.2 Unified Pipeline (One Stage Pipeline)

3.1節で紹介した重要な取り組みにより、より迅速かつ正確な検出器が得られ、
一般的なベンチマークデータセットの現在の主要な結果はすべて、
Faster RCNN [175]に基づいています。

その進歩にもかかわらず、領域ベースのアプローチは、
ストレージおよび計算能力が制限された
モバイル/ウェアラブルデバイスにとって 計算上高価 になる可能性がある。
    ↓
複雑な領域ベースのパイプラインの個々のコンポーネントを最適化するのではなく、
統一された検出戦略 を開発し始めた。


統一されたパイプライン
    単一のフィードフォワードCNNネットワークを用いて、
    領域の提案生成またはポスト分類を伴わないモノリシックな設定で、
    クラス確率およびバウンディングボックスオフセットを
    フル画像から直接予測するアーキテクチャを広く参照する。

    このアプローチは、
        単一のネットワークで すべての計算をカプセル化 して、
        領域提案の生成 および
        その後のピクセルまたはフィーチャの リサンプリング段階を完全に排除 する
        →   シンプルで洗練 されています

    検出パイプライン全体は単一のネットワーク
    →   検出性能に直接 エンドツーエンドで最適化 することができます


DetectorNet
    object bounding boxマスクに対する回帰問題を定式化します。

    AlexNet [109]を使用し、最終的なsoftmax分類層を回帰層で置き換えます。

    画像ウィンドウが与えられれば、
        1つのネットワークを使用して 粗いグリッド上の前景ピクセルを予測 するとともに、
        オブジェクトの上、下、左および右の半分を予測するための 4つの追加のネットワークを使用 する

    グループ化プロセスは、
        予測されたマスクを検出されたバウンディングボックスに変換する。


    オブジェクトタイプとマスクタイプごとにネットワークを訓練する必要があります。
    それは複数のクラスに拡張されません。

多くの作物を取り込んで、各作物ごとに各部分ごとに複数のネットワークを実行する必要がある。




OverFeat
    fully convolutional deep networksに基づく最初の現代の1段オブジェクト検出器の1つ

    ILSVRC2013ローカリゼーション競争に勝利し、最も成功したオブジェクト検出フレームワークの1つ

    （最終的な分類/回帰層を除いて）
    畳み込み層のみからなるCNNネットワークを通る単一の順方向パスを介して、
    マルチスケールスライディングウィンドウ方式 で オブジェクト検出 を実行する。
    →   自然に重複領域間で計算を共有します。


    特徴ベクトルの グリッドを生成 する。
        各グリッドは入力画像内のコンテキストビューの位置がわずかに異なり、
        オブジェクトの存在を予測することができる


    オブジェクトが識別されると、
    →   同じフィーチャを使用して、単一の境界ボックス回帰子を予測


    ネットワークを介して元画像の最大6つの拡大尺度を渡し、それらを繰り返して集約
    →   総合的な性能を向上させるためにマルチスケール機能を活用

    同じ期間に提案されたRCNNよりもはるかに高速ですが、
    その段階で完全な畳み込みネットワークを育成することは困難
    →   精度が大幅に低下します。

速度の利点
    完全畳み込みネットワークを用いて
    重なり合うウィンドウ間の畳み込み計算を共有することから得られる。



YOLO (You Only Look Once)
    画像ピクセルから空間的に分離されたバウンディングボックスおよび
    関連するクラス確率までの回帰問題として物体検出を統一する検出器

    領域プロポーザルの生成ステージが完全に削除されるため、
    →   候補領域の小さなセットを使用して検出を直接予測します。

    領域ベースのアプローチとは異なり、
        地方の地物の特徴に基づいて検出を予測する高速RCNNは、
        画像全体の特徴を世界的に使用します。

YOLO: 画像をS×Sグリッドに分割する。
    各グリッドは、
        Cクラスの確率、Bバウンディングボックスの位置、
        およびそれらのボックスの信頼スコアを予測します。

        これらの予測は、S×S×（5B + C）テンソルとして符号化される。

    地域提案提案の生成手順を完全に廃止することで、
    →   YOLOは設計上高速であり、45FPSでリアルタイムで実行され、
         高速バージョン、すなわち155FPSで動作するFastYOLO [174]が実行される。


YOLOは予測を行うときに画像全体を見るので、
→   オブジェクトクラスに関するコンテキスト情報を暗黙的にエンコードし、
    →   バックグラウンドでの誤検出を予測する可能性は低くなります。


YOLOは、
    バウンディングボックスの位置、縮尺、アスペクト比の大まかな分割の結果として、
    →   より多くのローカライゼーションエラーを発生させます。

[174]で議論されているように、
    YOLOはグリッド分割がかなり粗いため、
    いくつかのオブジェクト、特に小さなオブジェクトを
    ローカライズできない可能性があります。

YOLOが
    ILSVRC検出の課題など、かなり多くのオブジェクトを含むデータセットで
    良好なパフォーマンスにどの程度まで変換できるかは不明です。




YOLOv2 and YOLO9000
    YOLOの改良バージョン

    カスタムGoogLeNet [200]ネットワークがより単純なDarkNet19で置き換えられ、
    バッチ標準化[78] 完全に接続されたレイヤーを削除し、
    kmeansとマルチスケールトレーニングで学んだ良いアンカーボックスを使用します。

    PASCAL VOCやMS COCOのような標準的な検出タスクで最先端の技術を達成。

    RedmonとFarhadi [173]はYolO9000を導入
        YOLO9000は、
            複数のソースからのデータを結合するためにWordNetを使用して
            ImageNetとCOCOを同時に訓練する共同最適化方法を提案することにより、
            リアルタイムで9000種類以上のオブジェクトカテゴリを検出できます。


SSD (Single Shot Detector)
    YOLO [174]よりも速く、Faster RCNN [175]を含む
    最先端の領域ベースの検出器と競合する精度を有する

    あまりにも多くの検出精度を犠牲にすることなくリアルタイム速度を維持するために提案

    高速なRCNN [175]、YOLO [174]、multiscale CONV features[75]のRPNのアイデアを
    効果的に組み合わせて、
    →   高い検出品質を維持しながら高速な検出速度を実現

    YOLOと同様に、SSDは、
        これらのボックス内にオブジェクトクラスインスタンスが存在するかどうかについて
        固定数のバウンディングボックスとスコアを予測し、最後にNMSステップを実行
        →   最終検出を生成します。

    SSDのCNNネットワークは完全に畳み込みであり、
        初期層は基本ネットワークと呼ばれる
        VGG（分類層の前に切り捨てられている）などの標準アーキテクチャに基づく

    サイズが徐々に減少するいくつかの補助CONVレイヤがベースネットワークの最後に追加

    低解像度の最後のレイヤの情報は、空間的には粗すぎて、正確な定位ができないことがある
    →   SSDは、小さな物体を検出するためにより高い解像度の浅い層を使用

    サイズの異なるオブジェクトの場合、
        複数のCONV feature mapsで操作することにより、
        →   複数のスケールにわたって検出を実行
        
        複数のCONV feature mapsのそれぞれは、
           適切なサイズのbounding boxesのcategory scoresとbox offsetsを予測

300×300の入力の場合、
    SSDはNvidia Titan Xの59 FPSでのVOC2007テストで74.3％mAPを達成します。



4 Fundamental SubProblems
    フィーチャリプレゼンテーション、地域提案、コンテキスト情報マイニング、
    トレーニング戦略など、重要なサブ問題について


4.1 DCNN based Object Representation
4.1 DCNNベースのオブジェクト表現

いずれの検出器の主要構成要素の1つとして、
良好な特徴表現 が物体検出において第一の重要性を有する

過去には、
    SIFTやHOGなどのローカル記述子を設計し、
    その記述子をより高いレベルの表現にグループ化して抽象化する
    Bag of WordsやFisher Vectorなどのアプローチを
    探索することに多大な努力が払われてきたが、
    これらの特徴表現方法は、慎重なengineeringとかなりの領域の専門知識を必要とする



対照的に、
    複数の処理層で構成されたディープ学習法（特にディープCNNやDCNN）は、
    生の画像から直接複数の抽象レベルを持つ強力な特徴表現を学習することができる。

    学習手続きが伝統的なフィーチャ工学で必要とされる特定のドメイン知識と
    複雑な手続きの依存を減らすにつれて、
    →   フィーチャ表現の負担はより良いネットワークアーキテクチャの設計に移された。

主なフレームワークは、検出精度と速度を絶えず促進

CNN表現は重要な役割を果たし、
    検出器のエンジンであるのはCNNアーキテクチャであることは一般に認められている。

結果として、
    検出精度の最近の改善の大部分は、
    新規ネットワークの開発に関する研究によって達成されている。

したがって、
    まず、汎用オブジェクト検出で使用される一般的なCNNアーキテクチャを見直し、
    不変特徴の開発など、オブジェクトの特徴表現を改善するための努力を見直し、
    ↓
    物体のスケール、姿勢、視点、部品の変形の幾何学的変化に適応し、
    広範囲のスケールにわたって物体検出を改善するためのマルチスケール解析を実行する。


4.1.1 Popular CNN Architectures
4.1.1一般的なCNNアーキテクチャ

代表的なフレームワーク
    AlexNet、ZFNet、VGGNet、GoogLeNet、Inceptionシリーズ、ResNet、DenseNet、SENet

    これらは表2にまとめられており、
    オブジェクト認識におけるネットワークの改善は図9からわかる。
    最近のCNN進歩のさらなる見直しは、[71]に見出すことができる。


簡単に説明すると、
    CNNは
        階層構造を有し、畳み込み、非線形性、プールなどのような多数の層から構成される。

        より細かい層からより粗い層まで、
        画像は繰り返しフィルタリングされた畳み込みを受け、
        各層でこれらのフィルタの受容野（支持領域）が増加する。

    例えば、先駆的なAlexNet
        5つの畳み込みレイヤーと2つのFully Connected（FC）レイヤー
            第1レイヤーにはサイズ11×11×3の96個のフィルターを含む

            第1のCNN層: 低レベルのフィーチャ(エッジなど)を抽出
            中間層: 低レベルの特徴の組み合わせのような複雑さが増す特徴を抽出
            後の畳み込みレイヤ: オブジェクトをConclusions

    アーキテクチャの進化の傾向は、ネットワークConclusions
        AlexNetは8層、VGGNetは16層で構成され、Conclusions
        最近ではResNetとDenseNetの両方が100層のマークを上回り、
        特に、VGGNetとGoogLeNetで
        深層化が深層ネットワークの表現力を向上させることが示されました。

    興味深いことに、表2から分かるように、
    AlexNet、OverFeat、ZFNet、およびVGGNetなどのネットワークは、
    パラメータの大部分がFC層から来ているため、
    →   数層しかないにもかかわらず膨大な数のパラメータを有する。

        ↓
    Inception、ResNet、DenseNetなどの新しいネットワークは、
    ネットワーク深度が非常に大きいものの、
    FCレイヤーの使用を避けることで、パラメータが大幅に減少する。


    慎重に設計されたトポロジでInceptionモジュールを使用することで、
    GoogLeNetのパラメータが大幅に削減される。

    ResNetは、
        ILSVRC 2015分類作業に勝利し、
        何百ものレイヤーを持つ非常に深いネットワークを学習するためのスキップ接続の有効性を実証しました。


























p22
5.3 Performance
    PASCAL VOC [53,54]、ImageNet [179]、COCO [129]などの標準ベンチマークの導入により、
    検出器の精度を比較することが容易になりました。

    第3章と第4章の議論からわかるように、
    以下のような基本的/文脈上の点で異なる可能性があるため、
    精度、スピード、メモリだけで検出器を客観的に比較することは困難です。

    ・  RCNN [65]、高速RCNN [64]、高速RCNN [175]、RFCN [40]、マスクRCNN [80]、
        YOLO [174]およびSSD [136]などのメタ検出フレームワーク。

    ・  表2に示すVGG [191]、Inception [200,99,201]、ResNet [79]、
        ResNeXt [223]、Xception [35]、DetNet [127]などのバックボーンネットワーク。

    ・  多層的な特徴の組み合わせ[130,190,58]、変形可能な畳み込みネットワーク[41]、
        変形可能なRoIプーリング[160,41]、重い頭部[177,164]、軽い頭部[128]などの革新。

    ・  ImageNet [179]、COCO [129]、Places [245]、JFT [82]、
        Open Images [106]などのデータセットによる事前訓練

    ・  異なる検出提案手法と異なる数のオブジェクト提案。

    ・  マルチマイクロ、水平フリッピング、マルチスケール画像、
        新規マルチスケールトレーニング戦略[192、193]など、マスクの締め付け、
        およびモデルのアンサンブルなどのデータ補強の "トリック"のトレーニング/テスト。

    最近提案されたあらゆる検出器を比較することは実用的ではないかもしれないが、
    代表的かつ公に利用可能な検出器を共通プラットフォームに統合し、
    それらを統一的に比較することは非常に貴重である。



    バックボーンネットワーク、画像解像度、ボックス提案数などを変えることで、
    3つの主要な検出器（Faster RCNN、RFCNおよびSSD）ファミリの精度と速度との間の
    トレードオフのHuangの研究[96]を除いて、
    この点に関しては非常に限られた研究がなされている。


    表3、表4、表5、表6および表10からわかるように、
    広く使用されている3つの標準ベンチマークについて、
    多くの方法の中で最もよく報告されているパフォーマンスを要約しました。

    これらの方法の結果は、
    上に列挙された1つまたは複数の態様がそれぞれ異なるにもかかわらず、
    同じテストベンチマークで報告されました。


図1および図17は、
    PASCAL VOC、ILSVRCおよびMSCOCOの課題の最良の検出結果をまとめた
    最先端技術の概要を示しています。

より多くの結果が検出挑戦のウェブサイト[98、148、163]で見つかることができます。



検出の3つの最も重要な要素
    バックボーンネットワーク
    検出フレームワーク設計
    大規模データセットの可用性
    

より良い精度を達成するのに役立つ
    複数のモデルのアンサンブル
    コンテキストフィーチャの組み込み
    およびデータ拡大はすべて

5年未満では、AlexNet [109]が提案されて以来、
    図9に示すように1000クラスを持つImageNet分類[179]のTop5エラーは16％から2％に低下


しかし、
    COCO [129]上で最良の検出器[164]（80クラスを検出するように訓練されただけ）のmAPは、
    0.5 IoUにおいてさえ73％に達し、
    オブジェクト検出が画像分類よりもはるかに困難であるかを明確に示している。

    164.    Peng C., Xiao T., Li Z., Jiang Y., Zhang X., Jia K., Yu G., Sun J. (2018)
            MegDet: A large minibatch object detector. In: CVPR 20, 23

最先端の検出器によって達成される精度レベルは、
    汎用の実用的なアプリケーションの要件を満足するものではなく、
    将来の改善の余地がまだ残っています。



6 Conclusions

一般的な物体検出は、
    コンピュータビジョンにおいて重要かつ困難な問題であり、かなりの注目を集めている。

深い学習技術の顕著な発展のおかげで、オブジェクト検出の分野は劇的に進化しました。

この論文では、
    一般的なオブジェクト検出のための深い学習に関する包括的な調査として、
    最近の成果を強調し、検出における役割、要約された既存のデータセット
    および評価基準に従ってメソッドの構造分類を提供し、
    →   最も代表的なメソッドのパフォーマンスについて議論しました。


    過去数年間に達成された驚異的な成功にもかかわらず、
    （例えば、ILSVRC2013の23％からILSVRC2017の73％まで有意に改善する検出精度）
    特にオープンワールドの学習という点で、
    最先端と人間レベルのパフォーマンスの間には大きな隔たりがあります。


    次の8つの領域に焦点を当てていると、まだ多くの研究が行われています。

    
(1) Open World Learning:
（1）オープン・ワールド・ラーニング：
    究極の目標は、
        人間の視覚システムと競合するすべてのオープンワールドシーンで、
        すべてのオブジェクトカテゴリ（数千またはそれ以上のオブジェクトクラス[43]）の
        インスタンスを正確かつ効率的に認識およびローカライズできる
        オブジェクト検出システムを開発することです。

    最近のオブジェクト検出アルゴリズムは、
        限られたデータセットで学習され、
        データセットに含まれるオブジェクトカテゴリを認識してローカライズしますが、
        原則としてデータセット外の他のオブジェクトカテゴリには盲目的になります。
    理想的には、
        強力な検出システムは新規のオブジェクトカテゴリを認識できなければならない。

    現在の検出データセット[53,179,129]は、
        数十から数百までのカテゴリーしか含んでおらず、
        人間が認識できるものよりもはるかに小さい。

    この目標を達成するためには、
        CNNの最先端技術が十分に訓練するためには大量のデータを必要とするため、
        →   汎用オブジェクト検出のためにはるかに多くのカテゴリを持つ
             新しい大規模ラベル付きデータセットを開発する必要がある

    そのような膨大な量のデータ、
        特に物体検出のためのボックスラベルを収集することは、
        →   特に数十万のカテゴリにとって 非常に高価 である。



(2) Better and More Efficient Detection Frameworks:
（2）より効果的な検出フレームワーク：

    ジェネリックオブジェクト検出における大きな成功の要因の1つは、
        領域ベースおよび1状態検出器の両方で、より優れた検出フレームワークの開発
            領域ベース（RCNN [65]、Fast RCNN [64]、FasterRCNN [175]、マスクRCNN [80]）
            1状態検出器（YOLO [174]、SSD [136]）

        
    領域ベースの検出器は
        最高精度を有するが、
        組み込みシステムまたはリアルタイムシステムには計算量が多すぎる。

    1ステージ検出器は、
        より高速で簡単な可能性を秘めていますが、
        まだ領域ベースの検出器の精度には達していません。


1つの可能な制限は、
    最先端のオブジェクト検出器が基礎となる
    最初に画像分類のために最適化されたバックボーンネットワークに大きく依存した、
    
    DSOD検出器のように、
        1つの潜在的な戦略が物体検出器をゼロから学習することである
    
    という分類と検出の違いによる学習バイアスを引き起こすことである。


(3) Compact and Efficient Deep CNN Features:
（3）コンパクトで効率的な深いCNNの特徴：

generic object detectionにおける相当な進歩のもう一つの重要な要因は、
    数層(AlexNet)から数百層(ResNet, DenseNet)に顕著に深く増加した
    強力な深層CNNの開発であった。

これらのネットワークには
    数百万〜数億のパラメータがあり、
    訓練のために大量のデータとパワーが必要なGPUを必要とし、
    アプリケーションをリアルタイム/組み込みアプリケーションに限定します。

これに対応して、以下に関心が集まっている
    コンパクトで軽量なネットワーク
    ネットワークの圧縮と加速
    ネットワークの解釈と理解の設計
    


(4) Robust Object Representations:
（4）ロバストなオブジェクト表現：

    オブジェクト認識の問題を困難にする重要な要素の1つは、
        実世界のイメージの大きな変化
            視点や照明の変化
            オブジェクトのスケール
            オブジェクトのポーズ
            オブジェクトのパーツの変形
            背景のクラッタ
            オクルージョン
            外観の変化
            イメージのぼやけ
            イメージの解像度
            ノイズ
            カメラの限界および歪み
        を含む、様々な要因に依存する。


深いネットワークの進歩にもかかわらず、
    実際のアプリケーションのユーザビリティを著しく制限する
    これらの多くのバリエーションに対する堅牢性の欠如によって
    依然として制限されている。


(5) Context Reasoning:
（5）コンテキスト推論：

実際のオブジェクトは、通常、
    他のオブジェクトや環境と共存します。

文脈情報（オブジェクト関係、グローバルシーン統計）は、
    特にオブジェクトが小さくて隠れているか、画質が悪い場合に、
    
    →   オブジェクトの検出と認識に役立つことが認識されている[155]。


深い学習[143,152,171,47,59]に先行して広範な作業が行われていたが、
深い学習期以来、文脈情報を利用する進歩はごく限られていた[29,62,90]。

コンテキスト情報を効率的かつ効果的に取り込む方法は、
    人間が自然のシーンで関心のある対象物に
    どのように素早く関心を向けるかによって理想的には探求されています。


object instance segmentationは、
    個々のインスタンスの正確な境界を必要とする多くの潜在的なアプリケーションで
    重要な役割を果たす可能性があるため、
ピクセルレベルの object instance segmentation に取り組むことが、
    →   より豊かでより詳細なイメージコンテンツの理解に向かう傾向にあります。


(7) Weakly Supervised or Unsupervised Learning:
（7）弱監督または非監督の学習：

現在の最先端技術の検出器は、
    オブジェクトバウンディングボックスまたはセグメンテーションマスクを用いて
    ラベル付きデータから学んだ完全に監視されたモデルを使用するが、
    そのような完全に監視された学習は
    境界ボックス注釈の仮定が問題になる可能性がある場合、
    特にオブジェクトカテゴリの数が多い場合に重大な制限がある。

十分に監視された学習は、
    完全にラベル付けされたトレーニングデータがない場合にはスケーラブルではないため、
    弱い教師付きまたは非教師付きの検出で
    CNNの能力をどのように活用できるかを研究することは重要である[15,45,187]。


(8) 3D Object Detection:
（8）3Dオブジェクト検出：

深度カメラの進歩により、
    RGB-D画像または3D点群の形での奥行き情報の取得が可能になった。

深さモダリティは、
    物体の検出と認識を助けるために使用することができますが、
    この方向での作業は限られていますが、
    高品質のCADモデルの大きなコレクションを活用することで利益を得ることができる[219]。


generic object detectionの研究分野はまだ完全ではありません。
    過去5年間で大規模なアルゴリズムのブレークスルーがあったことから、
    今後5年間の機会について楽観的な姿勢を維持しています。
