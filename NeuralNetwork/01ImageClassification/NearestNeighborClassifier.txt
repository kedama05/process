Nearest Neighbor Classifier
この分類器は、畳み込みニューラルネットワークとは無関係。
実際にはほとんど使用されないが、イメージ分類問題に対する基本的なアプローチについてのアイデアを得ることができる。


CIFAR-10:
人気のあるおもちゃの画像分類データセットの1つ。
データセットは、高さと幅が32ピクセルである小さな画像、60,000個で構成されている。
各画像には10種類のクラス（例えば「飛行機、自動車、鳥など」）のラベルが付けられている。

60,000の画像は、50,000画像のトレーニングセットと10,000画像のテストセットに分割されている。


L1 distance: d1(I1,I2)=∑p|Ip1−Ip2|

2つの画像が同じ場合、結果はゼロになる。
しかし、イメージが非常に異なる場合、結果は大きくなる。

トレーニングデータ/ラベルとテストデータ/ラベルの4つの配列としてCIFAR-10データをメモリにロードする。
下のコードでは、Xtr（50,000 x 32 x 32 x 3のサイズで）
トレーニングセットのすべての画像を保持し、
対応する1次元配列Ytr（長さ50,000）がトレーニングラベル（0〜9）を保持する。
Xte,Yteはテスト用。

Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide
# flatten out all images to be one-dimensional
Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072
Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072

評価基準として、正しい予測の割合を測定するaccuracyを使用するのが一般的。
train(X,y): データとラベルを取得する関数
predict(X): 新しいデータを取り、ラベルを予測する関数

nn = NearestNeighbor() # create a Nearest Neighbor classifier class
nn.train(Xtr_rows, Ytr) # train the classifier on the training images and labels
Yte_predict = nn.predict(Xte_rows) # predict labels on the test images
# and now print the classification accuracy, which is the average number
# of examples that are correctly predicted (i.e. label matches)
print 'accuracy: %f' % ( np.mean(Yte_predict == Yte) )

L1距離の単純なNearest Neighborクラシファイアの実装を以下に示す。

import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in xrange(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred

この分類器はCIFAR-10で38.6％しか達成できない。
無作為な推測: 10のクラスがあるので10％の精度。

人間のパフォーマンス: 約94％
最先端の畳み込みニューラルネットワーク: 95％


The choice of distance. 

L2 distance: d2(I1,I2)=√∑_p (Ip1−Ip2)^2
2つのベクトル間のユークリッド距離を計算する幾何学的解釈を有する。
すべてを二乗して加算し、最後に平方根を取る.

numpyでは、上のコードを使用して、1行のコードだけを置き換える.

distances = np.sqrt( np.sum(np.square(self.Xtr - X[i,:]), axis = 1) )

実際の最近傍法では、平方根は数値の大小に関わらないので、平方根の計算を省くことができる。
この距離でCIFAR-10でNearest Neighborクラシファイアを実行した場合、
35.4％の精度（L1距離の結果よりわずかに低い）が得られる。

L1 vs. L2.







