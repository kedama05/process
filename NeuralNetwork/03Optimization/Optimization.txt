Optimizarion

前回までで2つの重要な要素を導入した
スコア関数: 生のイメージピクセルをクラススコア（例えば線形関数）にマッピングする。
損失関数:   スコアがトレーニングデータのground truthラベルとどの程度一致しているかで、
            特定のパラメータセットの品質を測定する。
            Softmax / SVMといった多くの方法がある。

具体的には、線形関数はf（xi、W）= Wxiの形式を持ち、我々が開発したSVMは以下のように定式化された：

L　=　1/N ∑i∑j≠yi [ max( 0,f(xi;W)j − f(xi;W)yi + 1 ) ] + αR(W)

ground truthラベルyiと一致するxiの予測を生成したパラメータWの設定もまた、
非常に低い損失Lを有することを見出した。

次に、3番目および最後の重要な要素、すなわち最適化を導入する。
最適化は、損失関数を最小にするパラメータWのセットを見つけるプロセスである。

Visualizing the loss function
損失関数の可視化


このクラスで見ている損失関数は、通常、
非常に高次元の空間で定義されているため、視覚化が困難である。
しかし、光線に沿った高次元空間（1次元）または平面（2次元）に沿って
スライスすることによって、まだ1つの直観を得ることができる。
例えば、ランダム重み行列WW1L（W + aW1）aaL（W + aW1 + bW2）a、ba、bを生成できる。


式から明らかなように、各例のデータ損失は、Wの最大（0、 - ）関数による線形関数のゼロしきい値との和である。

さらに、Wの各行（wj）は、その正面に正の符号（例では間違ったクラスに対応する）を有し、
ときには負の符号を有することもある（その例では正しいクラスに対応する）。

これをより明示するには、3つの1次元点と3つのクラスを含む単純なデータセットを考える。
完全なSVM損失（正則化なし）は次のようになる。
L0 = max(0,wT1x0−wT0x0+1)+max(0,wT2x0−wT0x0+1)
L1 = max(0,wT0x1−wT1x1+1)+max(0,wT2x1−wT1x1+1)
L2 = max(0,wT0x2−wT2x2+1)+max(0,wT1x2−wT2x2+1)
L = (L0+L1+L2)/3

これらの例は1次元なので、データxiと重みwjは数値である。
たとえば、w0を見ると、上の項はw0の線形関数であり、それぞれの項はゼロでクランプされている。

スコア関数fをニューラルネットワークに拡張すると、目的関数は非凸となり、
上記の視覚化はボウルを特徴とせず、複雑で不規則な地形になります。

微分不可能な損失関数。
テクニカルノートでは、これらのねじれで勾配が定義されていないため、
損失関数のねじれ（最大操作のため）によって技術的に損失関数を微分できないことがわかる。

しかし、劣勾配(サブグラディエント)はまだ存在し、代わりに一般的に使用されている。
ここでは、劣勾配と勾配という用語を同じ意味で使用する。


Optimization
最適化

繰り返すが、損失関数は、重みWの任意の特定の集合の品質を定量化することを可能にする。
最適化の目的は、損失関数を最小にするWを見つけることにある。

損失機能を最適化するためのアプローチを動機付けし、ゆっくりと開発する。
以前の経験でこのクラスに来る人にとっては、使用する実際の例が凸面の問題であるため、
このセクションは奇妙に思えるかもしれないが、我々の最終的な目標は、
Convex Optimizationの文献で開発されたツールを簡単に使用できないニューラルネットワークを最適化することである。





戦略＃1：非常に悪い解決策：ランダム検索
単純に多くの異なるランダムウェイトを試し、最良のものを追跡する
    いくつかのランダムな重みベクトルWを試し、
    検索で​​見つかった最良の重みWをテストセットで試す。

与えられたパラメータWがどれほど良いかをチェックするのはとても簡単。
最高のWを使用すると、約15.5％の精度が得られる。

コアアイデア: 反復的な改良
    ランダムなWで始まり、それを反復的に改良して毎回少しずつ改善する。
        重みWの最適な集合を見つけることは、非常に困難であるが、
        重みWの特定の集合をわずかに改善するという問題は、あまり難しくない。





目の不自由なハイカーの類推
    前進するのに役立つかもしれない1つのアナロジーは、
    目の不自由な丘陵地帯でハイキングをしていると考えて、底に達することを試みること。


戦略＃2：ランダムローカル検索
    初めの戦略は、片足をランダムな方向に広げ、
    それが下り坂をリードする場合にのみステップを取ること。

    具体的には、ランダムなWで始まり、ランダムな摂動 δW を生成し、
    摂動した W + δW での損失が低い場合、更新を実行する。

    この方法は優れた精度で分類できるが、無駄で計算時間がかかる。


戦略＃3：勾配に従う
    重みベクトルを変更するための最良の方向を計算する。
    この方向は、損失関数の勾配に関連する。

    ハイキングの類推においては、
    このアプローチはおおよそ丘の斜面を私たちの足元で感じ、
    最も急な感じの方向に向かうことに対応する。

    勾配は、入力空間内の各次元の傾きのベクトル。
    df(x)/dx = limh→0 f(x+h)−f(x) / h

    関心のある関数が単一の数ではなく複数のベクトルをとるとき、
    導関数を偏導関数と呼び、勾配は単純に各次元の偏微分のベクトルです。




Computing the gradient
勾配の計算

勾配を計算するには2つの方法がある。

1.  数値勾配: 遅く、近似的ではあるが簡単な方法
2.  計算勾配: 正確ではあるがエラーの起こりやすい方法


1.  数値勾配
有限差分で数値的に勾配を計算する
    下記の式は、数値的に勾配を計算することを可能にする。
    df(x)/dx = limh→0 f(x+h)−f(x) / h

    数学的定式化では、hがゼロに近づくにつれて勾配が限界に定義されるが、
    非常に小さい値を使用すれば十分である。
    
    実際には、中心差分式を使用して数値勾配を計算する方が効果的。
    [f(x+h)−f(x−h)]/2h

ステップサイズ（または後に学習レートと呼ぶ）は、
慎重に調整する必要がある最も重要なハイパーパラメータの1つである。

任意の点および任意の関数の勾配を計算することができる。
しかし、数値勾配を評価することは、パラメータの数が一様に複雑である。



2.  計算勾配
微積分で解析的に勾配を計算する
    数値勾配は有限差分近似を使用して計算するのは非常に簡単であるが、欠点は近似値。
    また、計算には計算コストが非常に高い。

    微積分を分析的に使用し、計算が非常に速い勾配（近似なし）の直接式を導き出す。
    ただし、数値勾配とは異なり、実装時によりエラーが起こりやすいため、
    解析勾配を計算して数値勾配と比較して実装の正確性を確認(勾配チェック)するのが一般的。

単一のデータポイントに対してSVM損失関数の例を使用できる。
    Li=∑j≠yi[max(0,wTjxi−wTyixi+Δ)]

重みに関して関数を区別することができる。wyiに関して勾配をとると、次のようになる。
    ∇wyi Li = −( ∑j≠yi 1( wTjxi−wTyixi+Δ > 0 ) )xi

ここで、1はインジケータ関数で、内部の条件が真の場合は1、そうでない場合はゼロ。

上の式は、目的のマージンを満たさない(損失関数に寄与する)クラスの数を数えるだけであり、
この数値でスケーリングされたデータベクトルxiは勾配である。
これは、正しいクラスに対応するWの行に関してのみ勾配であることに注意する。

j≠yiである他の行については、勾配は：
    ∇wjLi=1(wTjxi−wTyixi+Δ>0)xi
勾配の式を派生したら、式を実装して勾配の更新を実行するのは簡単。



Gradient Descent
勾配降下
    勾配を繰り返し評価し、パラメータ更新を実行する手順
    基本的な考え方: 結果に満足するまで勾配を追う

現在、勾配降下はニューラルネットワークの損失関数を最適化する最も一般的かつ確立された方法


# Vanilla Gradient Descent
while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # perform parameter update

最適化法を持たない基本的な勾配降下法 (Vanilla SGD)
    θt+1←θt−αgt



ミニバッチ勾配降下
    大規模なアプリケーションでは、単一のパラメータ更新のみを実行するために、
    トレーニングセット全体にわたって完全損失関数を計算することは無駄。
    →  トレーニングデータのバッチに対する勾配を計算する。
        このバッチを使用してパラメータの更新を実行する。


# Vanilla Minibatch Gradient Descent
while True:
  data_batch = sample_training_data(data, 256) # sample 256 examples
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # perform parameter update

ミニバッチを用いると、全データを用いて求める勾配に対する良い近似値が得られる。

確率勾配法（SGD）
    損失関数 E が、E(w→) = ∑i=1 n Ei(w→) のように、和の形で書ける場合を考える。
    データ数 n が多くなると、−∂E(w→)∂w→ の計算が非常に大変。

    −∂E(w→)/∂w→ の変わりに −∂Ei(w→)/∂w→ を使う。
    i は各反復で変える。
    Eの代わりにEiを使うことで、より多く反復を繰り返すことができる。

オンライン勾配降下法とも呼ぶ。

ミニバッチに1つの例しか含まれていない設定とも見れる。

                    バッチ                          ミニバッチ  オンライン
１回の反復の計算	全データを使うので計算が大変    ほどほど	データ１つしか使わないので計算が楽
１回の反復の精度	全データを使うので良さそう      ほどほど	データを１つしか使わないので変な方向に進むことがある